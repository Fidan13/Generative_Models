{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_KERAS=1\n",
      "\\\n"
     ]
    }
   ],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "\n",
    "import sys\n",
    "sys.path.append('..'+sep_local+'..')\n",
    "print(sep_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='pokemon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = 'C:\\\\projects\\\\pokemon\\DS06\\\\'\n",
    "VAL_PCT = 10\n",
    "VAL_FORMAT = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from training.generators.file_image_generator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEBUG    | Looking for images in 'all'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | 809 file found\n"
     ]
    }
   ],
   "source": [
    "imgs_list = create_image_lists(\n",
    "    image_dir=IMG_DIR, \n",
    "    validation_pct=VAL_PCT, \n",
    "    valid_imgae_formats=VAL_FORMAT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape= IMG_SIZE=(64, 64, 3)\n",
    "BATCH_SIZE = 32\n",
    "latent_dim = 100\n",
    "intermediate_dim = 100\n",
    "TRAIN_BUF = 600\n",
    "TEST_BUF = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 738 training files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 71 validation files\n"
     ]
    }
   ],
   "source": [
    "train_gen, test_gen = get_generators(\n",
    "    images_list=imgs_list, \n",
    "    image_dir=IMG_DIR, \n",
    "    image_size=IMG_SIZE, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_gen, \n",
    "    output_types=tf.float32 ,\n",
    "    output_shapes=tf.TensorShape((BATCH_SIZE, ) + IMG_SIZE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data[0].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_instance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(inputs_shape, Iterable):\n",
    "    _outputs_shape = np.prod(inputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_outputs_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lays = [tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=latent_dim)]\n",
    "\n",
    "dec_lays = [tf.keras.layers.Dense(units=latent_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=_outputs_shape),\n",
    "            tf.keras.layers.Reshape(inputs_shape)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'AAE'\n",
    "recoding_dir='..'+sep_local+'..'+sep_local+'recoding'+sep_local+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.adversarial.AAE import AAE as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape=IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latent_dim,\n",
    "        'layers': enc_lays#enc_lays2#\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latent_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays#dec_lays2#\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(recoding_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\recoding\\\\pokemonAAE\\\\var_save_dir'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exist(_restore)\n",
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to restore trained model, set filepath=_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inference\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64, 64, 100)       400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64, 64, 100)       10100     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 409600)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               40960100  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 40,971,000\n",
      "Trainable params: 40,970,800\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generative\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12288)             1241088   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 3)         12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,261,300\n",
      "Trainable params: 1,261,294\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    }
   ],
   "source": [
    "ae = AE( \n",
    "    name=model_name,\n",
    "    inputs_shape=inputs_shape,\n",
    "    outputs_shape=inputs_shape,\n",
    "    latent_dim=latent_dim,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pokemonAAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "inference (Model)            (None, 100)               40971000  \n",
      "_________________________________________________________________\n",
      "generative (Model)           (None, 64, 64, 3)         1261300   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_x_logits (Tensor [(None, 64, 64, 3)]       0         \n",
      "=================================================================\n",
      "Total params: 42,232,300\n",
      "Trainable params: 42,232,094\n",
      "Non-trainable params: 206\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#ae.compile(metrics=None)\n",
    "ae.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.callbacks.progress_bar import NotebookPrograssBar\n",
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "progbar = NotebookPrograssBar(leave_outer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore,save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\recoding\\\\pokemonAAE\\\\csv_dir\\\\pokemonAAE.csv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir = os.path.join(recoding_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, ae.name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(recoding_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latent_shape=latent_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training traditional basicAE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=2, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=50, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=50, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"latent_real_discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12288)             1241088   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 3)         12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "latent_real_discriminator_ou (None, 1)                 12289     \n",
      "=================================================================\n",
      "Total params: 1,273,589\n",
      "Trainable params: 1,273,583\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"latent_fake_discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12288)             1241088   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 3)         12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "latent_fake_discriminator_ou (None, 1)                 12289     \n",
      "=================================================================\n",
      "Total params: 1,273,589\n",
      "Trainable params: 1,273,583\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n",
      "training latent real discriminator\n",
      "Train for 50 steps\n",
      "Epoch 1/2\n",
      "50/50 [==============================] - ETA: 1:18 - loss: 0.293 - ETA: 42s - loss: 0.159 - ETA: 30s - loss: 0.11 - ETA: 24s - loss: 0.09 - ETA: 20s - loss: 0.07 - ETA: 18s - loss: 0.07 - ETA: 16s - loss: 0.06 - ETA: 14s - loss: 0.05 - ETA: 13s - loss: 0.05 - ETA: 12s - loss: 0.05 - ETA: 11s - loss: 0.05 - ETA: 10s - loss: 0.04 - ETA: 10s - loss: 0.04 - ETA: 9s - loss: 0.0455 - ETA: 9s - loss: 0.044 - ETA: 8s - loss: 0.043 - ETA: 8s - loss: 0.042 - ETA: 7s - loss: 0.041 - ETA: 7s - loss: 0.040 - ETA: 7s - loss: 0.039 - ETA: 6s - loss: 0.039 - ETA: 6s - loss: 0.038 - ETA: 6s - loss: 0.038 - ETA: 5s - loss: 0.037 - ETA: 5s - loss: 0.037 - ETA: 5s - loss: 0.036 - ETA: 5s - loss: 0.036 - ETA: 4s - loss: 0.036 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.035 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 1s - loss: 0.033 - ETA: 1s - loss: 0.032 - ETA: 1s - loss: 0.032 - ETA: 1s - loss: 0.032 - ETA: 1s - loss: 0.032 - ETA: 0s - loss: 0.032 - ETA: 0s - loss: 0.032 - ETA: 0s - loss: 0.032 - ETA: 0s - loss: 0.031 - 10s 199ms/step - loss: 0.0318\n",
      "Epoch 2/2\n",
      "50/50 [==============================] - ETA: 8s - loss: 0.026 - ETA: 8s - loss: 0.026 - ETA: 7s - loss: 0.026 - ETA: 7s - loss: 0.026 - ETA: 7s - loss: 0.026 - ETA: 7s - loss: 0.026 - ETA: 7s - loss: 0.026 - ETA: 7s - loss: 0.026 - ETA: 6s - loss: 0.026 - ETA: 6s - loss: 0.026 - ETA: 6s - loss: 0.026 - ETA: 6s - loss: 0.025 - ETA: 6s - loss: 0.025 - ETA: 6s - loss: 0.025 - ETA: 5s - loss: 0.025 - ETA: 5s - loss: 0.025 - ETA: 5s - loss: 0.025 - ETA: 5s - loss: 0.025 - ETA: 5s - loss: 0.025 - ETA: 5s - loss: 0.025 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.025 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 1s - loss: 0.025 - ETA: 1s - loss: 0.025 - ETA: 1s - loss: 0.025 - ETA: 1s - loss: 0.025 - ETA: 1s - loss: 0.025 - ETA: 1s - loss: 0.025 - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.025 - 9s 170ms/step - loss: 0.0252\n",
      "training latent fake discriminator\n",
      "Train for 50 steps\n",
      "Epoch 1/2\n",
      "50/50 [==============================] - ETA: 1:10 - loss: 0.275 - ETA: 39s - loss: 0.150 - ETA: 28s - loss: 0.10 - ETA: 22s - loss: 0.08 - ETA: 19s - loss: 0.07 - ETA: 17s - loss: 0.06 - ETA: 15s - loss: 0.06 - ETA: 14s - loss: 0.05 - ETA: 13s - loss: 0.05 - ETA: 12s - loss: 0.05 - ETA: 11s - loss: 0.04 - ETA: 10s - loss: 0.04 - ETA: 10s - loss: 0.04 - ETA: 9s - loss: 0.0445 - ETA: 9s - loss: 0.043 - ETA: 8s - loss: 0.042 - ETA: 8s - loss: 0.041 - ETA: 7s - loss: 0.040 - ETA: 7s - loss: 0.039 - ETA: 7s - loss: 0.039 - ETA: 6s - loss: 0.038 - ETA: 6s - loss: 0.038 - ETA: 6s - loss: 0.037 - ETA: 5s - loss: 0.037 - ETA: 5s - loss: 0.036 - ETA: 5s - loss: 0.036 - ETA: 5s - loss: 0.036 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 1s - loss: 0.032 - ETA: 1s - loss: 0.032 - ETA: 1s - loss: 0.032 - ETA: 1s - loss: 0.032 - ETA: 1s - loss: 0.032 - ETA: 0s - loss: 0.032 - ETA: 0s - loss: 0.031 - ETA: 0s - loss: 0.031 - ETA: 0s - loss: 0.031 - 10s 198ms/step - loss: 0.0315\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 8s - loss: 0.025 - ETA: 8s - loss: 0.025 - ETA: 7s - loss: 0.025 - ETA: 7s - loss: 0.025 - ETA: 7s - loss: 0.025 - ETA: 7s - loss: 0.025 - ETA: 7s - loss: 0.025 - ETA: 7s - loss: 0.025 - ETA: 6s - loss: 0.024 - ETA: 6s - loss: 0.024 - ETA: 6s - loss: 0.024 - ETA: 6s - loss: 0.024 - ETA: 6s - loss: 0.024 - ETA: 6s - loss: 0.024 - ETA: 5s - loss: 0.024 - ETA: 5s - loss: 0.024 - ETA: 5s - loss: 0.024 - ETA: 5s - loss: 0.024 - ETA: 5s - loss: 0.024 - ETA: 5s - loss: 0.024 - ETA: 4s - loss: 0.024 - ETA: 4s - loss: 0.024 - ETA: 4s - loss: 0.024 - ETA: 4s - loss: 0.024 - ETA: 4s - loss: 0.024 - ETA: 4s - loss: 0.023 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.023 - ETA: 2s - loss: 0.023 - ETA: 2s - loss: 0.023 - ETA: 2s - loss: 0.023 - ETA: 2s - loss: 0.023 - ETA: 2s - loss: 0.023 - ETA: 2s - loss: 0.023 - ETA: 1s - loss: 0.023 - ETA: 1s - loss: 0.023 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.022 - 9s 171ms/step - loss: 0.0224\n",
      "Model: \"latent_AA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inference_inputs (InputLayer)   [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inference (Model)               (None, 100)          40971000    inference_inputs[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           inference[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal/Rando [(None, 100)]        0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal/mul ( [(None, 100)]        0           tf_op_layer_random_normal/RandomS\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal (Tens [(None, 100)]        0           tf_op_layer_random_normal/mul[0][\n",
      "__________________________________________________________________________________________________\n",
      "generative (Model)              (None, 64, 64, 3)    1261300     inference[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent_fake_discriminator (Mode (None, 1)            1273589     inference[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent_real_discriminator (Mode (None, 1)            1273589     tf_op_layer_random_normal[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_x_logits_1 (TensorF [(None, 64, 64, 3)]  0           generative[2][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,779,478\n",
      "Trainable params: 44,779,260\n",
      "Non-trainable params: 218\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "training together\n",
      "Train for 50 steps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b413776fd1a24d51ab450b0a1e7598d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=2, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=50, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/50 [====================>.........] - ETA: 3:03 - loss: 5020.1182 - latent_fake_discriminator_outputs_loss: 19.2961 - latent_real_discriminator_outputs_loss: 1.5360 - x_logits_loss: 4999.1797 - x_logits_psnr: 8.9132 - x_logits_ssmi: 0.0080 - x_logits_sharp_diff: 4.90 - ETA: 1:34 - loss: 5147.1565 - latent_fake_discriminator_outputs_loss: 14.5769 - latent_real_discriminator_outputs_loss: 1.2684 - x_logits_loss: 5131.2051 - x_logits_psnr: 8.8123 - x_logits_ssmi: 0.0077 - x_logits_sharp_diff: 4.90 - ETA: 1:05 - loss: 5193.5021 - latent_fake_discriminator_outputs_loss: 10.2819 - latent_real_discriminator_outputs_loss: 1.2896 - x_logits_loss: 5181.8242 - x_logits_psnr: 8.7406 - x_logits_ssmi: 0.0079 - x_logits_sharp_diff: 4.90 - ETA: 50s - loss: 5151.6461 - latent_fake_discriminator_outputs_loss: 7.8213 - latent_real_discriminator_outputs_loss: 1.1397 - x_logits_loss: 5142.5786 - x_logits_psnr: 8.7686 - x_logits_ssmi: 0.0080 - x_logits_sharp_diff: 4.9140 - ETA: 40s - loss: 5071.5814 - latent_fake_discriminator_outputs_loss: 6.3542 - latent_real_discriminator_outputs_loss: 0.9460 - x_logits_loss: 5064.1748 - x_logits_psnr: 8.8308 - x_logits_ssmi: 0.0079 - x_logits_sharp_diff: 4.92 - ETA: 34s - loss: 5027.7708 - latent_fake_discriminator_outputs_loss: 5.3125 - latent_real_discriminator_outputs_loss: 0.8027 - x_logits_loss: 5021.5488 - x_logits_psnr: 8.8724 - x_logits_ssmi: 0.0080 - x_logits_sharp_diff: 4.92 - ETA: 30s - loss: 5066.5425 - latent_fake_discriminator_outputs_loss: 4.5536 - latent_real_discriminator_outputs_loss: 0.6896 - x_logits_loss: 5061.1924 - x_logits_psnr: 8.8642 - x_logits_ssmi: 0.0082 - x_logits_sharp_diff: 4.93 - ETA: 27s - loss: 5034.7989 - latent_fake_discriminator_outputs_loss: 3.9844 - latent_real_discriminator_outputs_loss: 0.6034 - x_logits_loss: 5030.1045 - x_logits_psnr: 8.8870 - x_logits_ssmi: 0.0083 - x_logits_sharp_diff: 4.93 - ETA: 24s - loss: 5020.8373 - latent_fake_discriminator_outputs_loss: 3.5417 - latent_real_discriminator_outputs_loss: 0.5385 - x_logits_loss: 5016.6504 - x_logits_psnr: 8.9033 - x_logits_ssmi: 0.0083 - x_logits_sharp_diff: 4.94 - ETA: 22s - loss: 5065.0396 - latent_fake_discriminator_outputs_loss: 3.1992 - latent_real_discriminator_outputs_loss: 0.5006 - x_logits_loss: 5061.2334 - x_logits_psnr: 8.8533 - x_logits_ssmi: 0.0084 - x_logits_sharp_diff: 4.93 - ETA: 20s - loss: 5072.3666 - latent_fake_discriminator_outputs_loss: 2.9324 - latent_real_discriminator_outputs_loss: 0.4641 - x_logits_loss: 5068.8633 - x_logits_psnr: 8.8510 - x_logits_ssmi: 0.0084 - x_logits_sharp_diff: 4.93 - ETA: 18s - loss: 5059.4301 - latent_fake_discriminator_outputs_loss: 2.6886 - latent_real_discriminator_outputs_loss: 0.4254 - x_logits_loss: 5056.2090 - x_logits_psnr: 8.8611 - x_logits_ssmi: 0.0084 - x_logits_sharp_diff: 4.93 - ETA: 17s - loss: 5033.9100 - latent_fake_discriminator_outputs_loss: 2.4819 - latent_real_discriminator_outputs_loss: 0.3927 - x_logits_loss: 5030.9282 - x_logits_psnr: 8.8825 - x_logits_ssmi: 0.0084 - x_logits_sharp_diff: 4.94 - ETA: 16s - loss: 5031.8702 - latent_fake_discriminator_outputs_loss: 2.3046 - latent_real_discriminator_outputs_loss: 0.3841 - x_logits_loss: 5029.0742 - x_logits_psnr: 8.8902 - x_logits_ssmi: 0.0085 - x_logits_sharp_diff: 4.94 - ETA: 15s - loss: 5034.1913 - latent_fake_discriminator_outputs_loss: 2.1510 - latent_real_discriminator_outputs_loss: 0.3585 - x_logits_loss: 5031.5747 - x_logits_psnr: 8.8853 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.94 - ETA: 14s - loss: 5029.0616 - latent_fake_discriminator_outputs_loss: 2.0165 - latent_real_discriminator_outputs_loss: 0.3364 - x_logits_loss: 5026.6016 - x_logits_psnr: 8.8887 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.94 - ETA: 13s - loss: 5042.6953 - latent_fake_discriminator_outputs_loss: 1.8979 - latent_real_discriminator_outputs_loss: 0.3166 - x_logits_loss: 5040.3735 - x_logits_psnr: 8.8801 - x_logits_ssmi: 0.0085 - x_logits_sharp_diff: 4.94 - ETA: 12s - loss: 5029.7416 - latent_fake_discriminator_outputs_loss: 1.7925 - latent_real_discriminator_outputs_loss: 0.2990 - x_logits_loss: 5027.5430 - x_logits_psnr: 8.8918 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.94 - ETA: 12s - loss: 5012.0106 - latent_fake_discriminator_outputs_loss: 1.6981 - latent_real_discriminator_outputs_loss: 0.2870 - x_logits_loss: 5009.9180 - x_logits_psnr: 8.9092 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.94 - ETA: 11s - loss: 5019.5980 - latent_fake_discriminator_outputs_loss: 1.6132 - latent_real_discriminator_outputs_loss: 0.2760 - x_logits_loss: 5017.6016 - x_logits_psnr: 8.9001 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.95 - ETA: 10s - loss: 5105.1785 - latent_fake_discriminator_outputs_loss: 1.5364 - latent_real_discriminator_outputs_loss: 0.2628 - x_logits_loss: 5103.2720 - x_logits_psnr: 8.8256 - x_logits_ssmi: 0.0085 - x_logits_sharp_diff: 4.94 - ETA: 10s - loss: 5102.7274 - latent_fake_discriminator_outputs_loss: 1.4666 - latent_real_discriminator_outputs_loss: 0.2509 - x_logits_loss: 5100.9028 - x_logits_psnr: 8.8309 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.94 - ETA: 9s - loss: 5113.4084 - latent_fake_discriminator_outputs_loss: 1.4028 - latent_real_discriminator_outputs_loss: 0.2400 - x_logits_loss: 5111.6582 - x_logits_psnr: 8.8186 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.9443 - ETA: 9s - loss: 5100.2892 - latent_fake_discriminator_outputs_loss: 1.3444 - latent_real_discriminator_outputs_loss: 0.2300 - x_logits_loss: 5098.6074 - x_logits_psnr: 8.8271 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.945 - ETA: 8s - loss: 5097.5631 - latent_fake_discriminator_outputs_loss: 1.2906 - latent_real_discriminator_outputs_loss: 0.2208 - x_logits_loss: 5095.9443 - x_logits_psnr: 8.8281 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.945 - ETA: 8s - loss: 5092.2711 - latent_fake_discriminator_outputs_loss: 1.2410 - latent_real_discriminator_outputs_loss: 0.2123 - x_logits_loss: 5090.7104 - x_logits_psnr: 8.8293 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.945 - ETA: 7s - loss: 5089.1032 - latent_fake_discriminator_outputs_loss: 1.1950 - latent_real_discriminator_outputs_loss: 0.2045 - x_logits_loss: 5087.5962 - x_logits_psnr: 8.8313 - x_logits_ssmi: 0.0086 - x_logits_sharp_diff: 4.945 - ETA: 7s - loss: 5083.5461 - latent_fake_discriminator_outputs_loss: 1.1523 - latent_real_discriminator_outputs_loss: 0.2025 - x_logits_loss: 5082.0835 - x_logits_psnr: 8.8354 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.947 - ETA: 6s - loss: 5075.1177 - latent_fake_discriminator_outputs_loss: 1.1126 - latent_real_discriminator_outputs_loss: 0.1955 - x_logits_loss: 5073.7021 - x_logits_psnr: 8.8421 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.948 - ETA: 6s - loss: 5066.8122 - latent_fake_discriminator_outputs_loss: 1.0755 - latent_real_discriminator_outputs_loss: 0.1890 - x_logits_loss: 5065.4399 - x_logits_psnr: 8.8492 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.949 - ETA: 6s - loss: 5057.4192 - latent_fake_discriminator_outputs_loss: 1.0408 - latent_real_discriminator_outputs_loss: 0.1829 - x_logits_loss: 5056.0879 - x_logits_psnr: 8.8590 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.949 - ETA: 5s - loss: 5056.7454 - latent_fake_discriminator_outputs_loss: 1.0083 - latent_real_discriminator_outputs_loss: 0.1772 - x_logits_loss: 5055.4521 - x_logits_psnr: 8.8572 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.949 - ETA: 5s - loss: 5045.6125 - latent_fake_discriminator_outputs_loss: 0.9778 - latent_real_discriminator_outputs_loss: 0.1718 - x_logits_loss: 5044.3550 - x_logits_psnr: 8.8688 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.951 - ETA: 4s - loss: 5038.4013 - latent_fake_discriminator_outputs_loss: 0.9490 - latent_real_discriminator_outputs_loss: 0.1668 - x_logits_loss: 5037.1777 - x_logits_psnr: 8.8742 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.951 - ETA: 4s - loss: 5029.9085 - latent_fake_discriminator_outputs_loss: 0.9219 - latent_real_discriminator_outputs_loss: 0.1620 - x_logits_loss: 5028.7168 - x_logits_psnr: 8.8828 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.952 - ETA: 4s - loss: 5027.5494 - latent_fake_discriminator_outputs_loss: 0.8963 - latent_real_discriminator_outputs_loss: 0.1575 - x_logits_loss: 5026.3882 - x_logits_psnr: 8.8859 - x_logits_ssmi: 0.0087 - x_logits_sharp_diff: 4.9538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50 [============================>.] - ETA: 3s - loss: 5022.1155 - latent_fake_discriminator_outputs_loss: 0.8721 - latent_real_discriminator_outputs_loss: 0.1533 - x_logits_loss: 5020.9829 - x_logits_psnr: 8.8896 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.954 - ETA: 3s - loss: 5025.1555 - latent_fake_discriminator_outputs_loss: 0.8507 - latent_real_discriminator_outputs_loss: 0.1492 - x_logits_loss: 5024.0483 - x_logits_psnr: 8.8856 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.955 - ETA: 3s - loss: 5024.2637 - latent_fake_discriminator_outputs_loss: 0.8304 - latent_real_discriminator_outputs_loss: 0.1454 - x_logits_loss: 5023.1807 - x_logits_psnr: 8.8848 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.956 - ETA: 2s - loss: 5021.6213 - latent_fake_discriminator_outputs_loss: 0.8096 - latent_real_discriminator_outputs_loss: 0.1418 - x_logits_loss: 5020.5625 - x_logits_psnr: 8.8849 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.957 - ETA: 2s - loss: 5013.9888 - latent_fake_discriminator_outputs_loss: 0.7899 - latent_real_discriminator_outputs_loss: 0.1383 - x_logits_loss: 5012.9531 - x_logits_psnr: 8.8909 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.956 - ETA: 2s - loss: 5007.8501 - latent_fake_discriminator_outputs_loss: 0.7711 - latent_real_discriminator_outputs_loss: 0.1350 - x_logits_loss: 5006.8369 - x_logits_psnr: 8.8943 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.956 - ETA: 2s - loss: 5015.9310 - latent_fake_discriminator_outputs_loss: 0.7531 - latent_real_discriminator_outputs_loss: 0.1319 - x_logits_loss: 5014.9385 - x_logits_psnr: 8.8863 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.956 - ETA: 1s - loss: 5013.2294 - latent_fake_discriminator_outputs_loss: 0.7360 - latent_real_discriminator_outputs_loss: 0.1289 - x_logits_loss: 5012.2573 - x_logits_psnr: 8.8872 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.957 - ETA: 1s - loss: 5031.2880 - latent_fake_discriminator_outputs_loss: 0.7197 - latent_real_discriminator_outputs_loss: 0.1260 - x_logits_loss: 5030.3350 - x_logits_psnr: 8.8710 - x_logits_ssmi: 0.0088 - x_logits_sharp_diff: 4.956 - ETA: 1s - loss: 5026.8033 - latent_fake_discriminator_outputs_loss: 0.7040 - latent_real_discriminator_outputs_loss: 0.1233 - x_logits_loss: 5025.8687 - x_logits_psnr: 8.8741 - x_logits_ssmi: 0.0089 - x_logits_sharp_diff: 4.956 - ETA: 0s - loss: 5028.4939 - latent_fake_discriminator_outputs_loss: 0.6890 - latent_real_discriminator_outputs_loss: 0.1207 - x_logits_loss: 5027.5767 - x_logits_psnr: 8.8711 - x_logits_ssmi: 0.0089 - x_logits_sharp_diff: 4.956 - ETA: 0s - loss: 5029.9766 - latent_fake_discriminator_outputs_loss: 0.6747 - latent_real_discriminator_outputs_loss: 0.1181 - x_logits_loss: 5029.0762 - x_logits_psnr: 8.8691 - x_logits_ssmi: 0.0089 - x_logits_sharp_diff: 4.955 - ETA: 0s - loss: 5033.7517 - latent_fake_discriminator_outputs_loss: 0.6609 - latent_real_discriminator_outputs_loss: 0.1157 - x_logits_loss: 5032.8672 - x_logits_psnr: 8.8641 - x_logits_ssmi: 0.0089 - x_logits_sharp_diff: 4.9556WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ..\\..\\recoding\\pokemonAAE\\var_save_dir\\assets\n",
      "\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'psnr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-092f8ddd148e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32mc:\\projects\\Generatives\\Generative_Models\\training\\adversarial\\AAE.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, input_kw, input_scale, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         )\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m     \u001b[0mrow_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m     \u001b[0mrow_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'psnr'"
     ]
    }
   ],
   "source": [
    "ae.fit(\n",
    "    x=train_ds,\n",
    "    input_kw=None,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=2, #int(1e6)\n",
    "    verbose=0,\n",
    "    callbacks=[progbar, es, ms, csv_log, sg],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
