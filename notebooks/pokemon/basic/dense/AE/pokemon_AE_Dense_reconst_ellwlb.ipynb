{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_KERAS=1\n",
      "\\\n"
     ]
    }
   ],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "\n",
    "import sys\n",
    "sys.path.append('..'+sep_local+'..')\n",
    "print(sep_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalid\\Documents\\projects\\GM\\Generative_Models\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='pokemon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'C:\\\\Users\\\\Khalid\\\\Documents\\projects\\\\pokemon\\DS06\\\\'\n",
    "validation_percentage = 20\n",
    "valid_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from training.generators.file_image_generator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEBUG    | Looking for images in 'all'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | 809 file found\n"
     ]
    }
   ],
   "source": [
    "imgs_list = create_image_lists(\n",
    "    image_dir=images_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape= image_size=(200, 200, 3)\n",
    "batch_size = 32\n",
    "latents_dim = 32\n",
    "intermediate_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 662 training files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 147 validation files\n"
     ]
    }
   ],
   "source": [
    "training_generator, testing_generator = get_generators(\n",
    "    images_list=imgs_list, \n",
    "    image_dir=images_dir, \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size, \n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values obtained by Wang et al.\n",
    "_MSSSIM_WEIGHTS = (0.0448, 0.2856, 0.3001, 0.2363, 0.1333)\n",
    "\n",
    "def ssim_multiscale(img1,\n",
    "                    img2,\n",
    "                    max_val,\n",
    "                    power_factors=_MSSSIM_WEIGHTS,\n",
    "                    filter_size=11,\n",
    "                    filter_sigma=1.5,\n",
    "                    k1=0.01,\n",
    "                    k2=0.03):\n",
    "    \"\"\"Computes the MS-SSIM between img1 and img2.\n",
    "    This function assumes that `img1` and `img2` are image batches, i.e. the last\n",
    "    three dimensions are [height, width, channels].\n",
    "    Note: The true SSIM is only defined on grayscale.  This function does not\n",
    "    perform any colorspace transform.  (If input is already YUV, then it will\n",
    "    compute YUV SSIM average.)\n",
    "    Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. \"Multiscale\n",
    "    structural similarity for image quality assessment.\" Signals, Systems and\n",
    "    Computers, 2004.\n",
    "    Arguments:\n",
    "    img1: First image batch.\n",
    "    img2: Second image batch. Must have the same rank as img1.\n",
    "    max_val: The dynamic range of the images (i.e., the difference between the\n",
    "      maximum the and minimum allowed values).\n",
    "    power_factors: Iterable of weights for each of the scales. The number of\n",
    "      scales used is the length of the list. Index 0 is the unscaled\n",
    "      resolution's weight and each increasing scale corresponds to the image\n",
    "      being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,\n",
    "      0.1333), which are the values obtained in the original paper.\n",
    "    filter_size: Default value 11 (size of gaussian filter).\n",
    "    filter_sigma: Default value 1.5 (width of gaussian filter).\n",
    "    k1: Default value 0.01\n",
    "    k2: Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so\n",
    "      it would be better if we taken the values in range of 0< K2 <0.4).\n",
    "    Returns:\n",
    "    A tensor containing an MS-SSIM value for each image in batch.  The values\n",
    "    are in range [0, 1].  Returns a tensor with shape:\n",
    "    broadcast(img1.shape[:-3], img2.shape[:-3]).\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to tensor if needed.\n",
    "    img1 = tf.convert_to_tensor(img1, name='img1')\n",
    "    img2 = tf.convert_to_tensor(img2, name='img2')\n",
    "    # Shape checking.\n",
    "    shape1, shape2 = img1.shape, img2.shape\n",
    "\n",
    "    # Need to convert the images to float32.  Scale max_val accordingly so that\n",
    "    # SSIM is computed correctly.\n",
    "    max_val = tf.cast(max_val, dtype='float32')\n",
    "    img1 = tf.cast(img1, dtype='float32')\n",
    "    img2 = tf.cast(img2, dtype='float32')\n",
    "\n",
    "    imgs = [img1, img2]\n",
    "    shapes = [shape1, shape2]\n",
    "\n",
    "    # img1 and img2 are assumed to be a (multi-dimensional) batch of\n",
    "    # 3-dimensional images (height, width, channels). `heads` contain the batch\n",
    "    # dimensions, and `tails` contain the image dimensions.\n",
    "    heads = [s[:-3] for s in shapes]\n",
    "    tails = [s[-3:] for s in shapes]\n",
    "\n",
    "    divisor = [1, 2, 2, 1]\n",
    "    divisor_tensor = tf.constant(divisor[1:], dtype=\"int32\")\n",
    "\n",
    "    def do_pad(images, remainder):\n",
    "        padding = tf.expand_dims(remainder, -1)\n",
    "        padding = tf.pad(padding, [[1, 0], [1, 0]])\n",
    "        return [tf.pad(x, padding, mode='SYMMETRIC') for x in images]\n",
    "\n",
    "    mcs = []\n",
    "    for k in range(len(power_factors)):\n",
    "        if k > 0:\n",
    "            # Avg pool takes rank 4 tensors. Flatten leading dimensions.\n",
    "            flat_imgs = [\n",
    "              tf.reshape(x, tf.concat([[-1], t], 0))\n",
    "              for x, t in zip(imgs, tails)\n",
    "            ]\n",
    "\n",
    "            remainder = tails[0] % divisor_tensor\n",
    "            need_padding = tf.reduce_any(tf.not_equal(remainder, 0))\n",
    "            # pylint: disable=cell-var-from-loop\n",
    "            padded = tf.cond(need_padding,\n",
    "                                         lambda: do_pad(flat_imgs, remainder),\n",
    "                                         lambda: flat_imgs)\n",
    "            # pylint: enable=cell-var-from-loop\n",
    "\n",
    "            downscaled = [\n",
    "              tf.nn.avg_pool(\n",
    "                  x, ksize=divisor, strides=divisor, padding='VALID')\n",
    "              for x in padded\n",
    "            ]\n",
    "            tails = [x[1:] for x in tf.shape_n(downscaled)]\n",
    "            imgs = [\n",
    "              tf.reshape(x, tf.concat([h, t], 0))\n",
    "              for x, h, t in zip(downscaled, heads, tails)\n",
    "            ]\n",
    "\n",
    "        # Overwrite previous ssim value since we only need the last one.\n",
    "        ssim_per_channel, cs = _ssim_per_channel(\n",
    "            *imgs,\n",
    "            max_val=max_val,\n",
    "            filter_size=filter_size,\n",
    "            filter_sigma=filter_sigma,\n",
    "            k1=k1,\n",
    "            k2=k2)\n",
    "        mcs.append(tf.nn.relu(cs))\n",
    "\n",
    "    # Remove the cs score for the last scale. In the MS-SSIM calculation,\n",
    "    # we use the l(p) at the highest scale. l(p) * cs(p) is ssim(p).\n",
    "    mcs.pop()  # Remove the cs score for the last scale.\n",
    "    mcs_and_ssim = tf.stack(\n",
    "        mcs + [tf.nn.relu(ssim_per_channel)], axis=-1)\n",
    "    # Take weighted geometric mean across the scale axis.\n",
    "    ms_ssim = tf.reduce_prod(\n",
    "        tf.pow(mcs_and_ssim, power_factors), [-1])\n",
    "\n",
    "    return tf.reduce_mean(ms_ssim, [-1])  # Avg over color channels.\n",
    "\n",
    "def _fspecial_gauss(size, sigma):\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function.\"\"\"\n",
    "    size = tf.convert_to_tensor(size, dtype='int32')\n",
    "    sigma = tf.convert_to_tensor(sigma)\n",
    "\n",
    "    coords = tf.cast(tf.range(size), sigma.dtype)\n",
    "    coords -= tf.cast(size - 1, sigma.dtype) / 2.0\n",
    "\n",
    "    g = tf.square(coords)\n",
    "    g *= -0.5 / tf.square(sigma)\n",
    "\n",
    "    g = tf.reshape(g, shape=[1, -1]) + tf.reshape(g, shape=[-1, 1])\n",
    "    g = tf.reshape(g, shape=[1, -1])  # For tf.nn.softmax().\n",
    "    g = tf.nn.softmax(g)\n",
    "    return tf.reshape(g, shape=[size, size, 1, 1])\n",
    "\n",
    "def _ssim_per_channel(img1,\n",
    "                      img2,\n",
    "                      max_val=1.0,\n",
    "                      filter_size=11,\n",
    "                      filter_sigma=1.5,\n",
    "                      k1=0.01,\n",
    "                      k2=0.03):\n",
    "    \"\"\"Computes SSIM index between img1 and img2 per color channel.\n",
    "    This function matches the standard SSIM implementation from:\n",
    "    Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image\n",
    "    quality assessment: from error visibility to structural similarity. IEEE\n",
    "    transactions on image processing.\n",
    "    Details:\n",
    "    - 11x11 Gaussian filter of width 1.5 is used.\n",
    "    - k1 = 0.01, k2 = 0.03 as in the original paper.\n",
    "    Args:\n",
    "    img1: First image batch.\n",
    "    img2: Second image batch.\n",
    "    max_val: The dynamic range of the images (i.e., the difference between the\n",
    "      maximum the and minimum allowed values).\n",
    "    filter_size: Default value 11 (size of gaussian filter).\n",
    "    filter_sigma: Default value 1.5 (width of gaussian filter).\n",
    "    k1: Default value 0.01\n",
    "    k2: Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so\n",
    "      it would be better if we taken the values in range of 0< K2 <0.4).\n",
    "    Returns:\n",
    "    A pair of tensors containing and channel-wise SSIM and contrast-structure\n",
    "    values. The shape is [..., channels].\n",
    "    \"\"\"\n",
    "    filter_size = tf.constant(filter_size, dtype='int32')\n",
    "    filter_sigma = tf.constant(filter_sigma, dtype=img1.dtype)\n",
    "\n",
    "    shape1, shape2 = tf.shape(img1), tf.shape(img2)\n",
    "\n",
    "    \n",
    "    # TODO(sjhwang): Try to cache kernels and compensation factor.\n",
    "    kernel = _fspecial_gauss(filter_size, filter_sigma)\n",
    "    kernel = tf.tile(kernel, multiples=[1, 1, shape1[-1], 1])\n",
    "\n",
    "    # The correct compensation factor is `1.0 - tf.reduce_sum(tf.square(kernel))`,\n",
    "    # but to match MATLAB implementation of MS-SSIM, we use 1.0 instead.\n",
    "    compensation = 1.0\n",
    "\n",
    "    # TODO(sjhwang): Try FFT.\n",
    "    # TODO(sjhwang): Gaussian kernel is separable in space. Consider applying\n",
    "    #   1-by-n and n-by-1 Gaussain filters instead of an n-by-n filter.\n",
    "    def reducer(x):\n",
    "        shape = tf.shape(x)\n",
    "        x = tf.reshape(x, shape=tf.concat([[-1], shape[-3:]], 0))\n",
    "        y = tf.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        return tf.reshape(\n",
    "            y, tf.concat([shape[:-3], tf.shape(y)[1:]], 0))\n",
    "\n",
    "    luminance, cs = _ssim_helper(img1, img2, reducer, max_val, compensation, k1,\n",
    "                               k2)\n",
    "\n",
    "    # Average over the second and the third from the last: height, width.\n",
    "    axes = tf.constant([-3, -2], dtype=\"int32\")\n",
    "    ssim_val = tf.reduce_mean(luminance * cs, axes)\n",
    "    cs = tf.reduce_mean(cs, axes)\n",
    "    return ssim_val, cs\n",
    "\n",
    "def _ssim_helper(x, y, reducer, max_val, compensation=1.0, k1=0.01, k2=0.03):\n",
    "    \"\"\"Helper function for computing SSIM.\n",
    "      SSIM estimates covariances with weighted sums.  The default parameters\n",
    "      use a biased estimate of the covariance:\n",
    "      Suppose `reducer` is a weighted sum, then the mean estimators are\n",
    "        \\mu_x = \\sum_i w_i x_i,\n",
    "        \\mu_y = \\sum_i w_i y_i,\n",
    "      where w_i's are the weighted-sum weights, and covariance estimator is\n",
    "        cov_{xy} = \\sum_i w_i (x_i - \\mu_x) (y_i - \\mu_y)\n",
    "      with assumption \\sum_i w_i = 1. This covariance estimator is biased, since\n",
    "        E[cov_{xy}] = (1 - \\sum_i w_i ^ 2) Cov(X, Y).\n",
    "      For SSIM measure with unbiased covariance estimators, pass as `compensation`\n",
    "      argument (1 - \\sum_i w_i ^ 2).\n",
    "      Arguments:\n",
    "        x: First set of images.\n",
    "        y: Second set of images.\n",
    "        reducer: Function that computes 'local' averages from set of images. For\n",
    "          non-convolutional version, this is usually tf.reduce_mean(x, [1, 2]), and\n",
    "          for convolutional version, this is usually tf.nn.avg_pool2d or\n",
    "          tf.nn.conv2d with weighted-sum kernel.\n",
    "        max_val: The dynamic range (i.e., the difference between the maximum\n",
    "          possible allowed value and the minimum allowed value).\n",
    "        compensation: Compensation factor. See above.\n",
    "        k1: Default value 0.01\n",
    "        k2: Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so\n",
    "          it would be better if we taken the values in range of 0< K2 <0.4).\n",
    "      Returns:\n",
    "        A pair containing the luminance measure, and the contrast-structure measure.\n",
    "    \"\"\"\n",
    "\n",
    "    c1 = (k1 * max_val)**2\n",
    "    c2 = (k2 * max_val)**2\n",
    "\n",
    "    # SSIM luminance measure is\n",
    "    # (2 * mu_x * mu_y + c1) / (mu_x ** 2 + mu_y ** 2 + c1).\n",
    "    mean0 = reducer(x)\n",
    "    mean1 = reducer(y)\n",
    "    num0 = mean0 * mean1 * 2.0\n",
    "    den0 = tf.square(mean0) + tf.square(mean1)\n",
    "    luminance = (num0 + c1) / (den0 + c1)\n",
    "\n",
    "    # SSIM contrast-structure measure is\n",
    "    #   (2 * cov_{xy} + c2) / (cov_{xx} + cov_{yy} + c2).\n",
    "    # Note that `reducer` is a weighted sum with weight w_k, \\sum_i w_i = 1, then\n",
    "    #   cov_{xy} = \\sum_i w_i (x_i - \\mu_x) (y_i - \\mu_y)\n",
    "    #          = \\sum_i w_i x_i y_i - (\\sum_i w_i x_i) (\\sum_j w_j y_j).\n",
    "    num1 = reducer(x * y) * 2.0\n",
    "    den1 = reducer(tf.square(x) + tf.square(y))\n",
    "    c2 *= compensation\n",
    "    cs = (num1 - num0 + c2) / (den1 - den0 + c2)\n",
    "\n",
    "    # SSIM score is the product of the luminance and contrast-structure measures.\n",
    "    return luminance, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = next(training_generator)\n",
    "batch2 = next(training_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([0.16965742, 0.        , 0.        , 0.20615137, 0.03111482,\n",
       "       0.2144474 , 0.12817983, 0.19708337, 0.        , 0.27186373,\n",
       "       0.23284304, 0.        , 0.01829755, 0.        , 0.18802299,\n",
       "       0.13734509, 0.11309292, 0.        , 0.24793322, 0.23608035,\n",
       "       0.15242974, 0.20381433, 0.10596115, 0.08997952, 0.        ,\n",
       "       0.06566537, 0.06928582, 0.11059143, 0.18478839, 0.18571554,\n",
       "       0.07921096, 0.2950584 ], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim_multiscale(batch1, batch2, max_val=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: training_generator, \n",
    "    output_types=tf.float32 ,\n",
    "    output_shapes=tf.TensorShape((batch_size, ) + image_size)\n",
    ")\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: testing_generator, \n",
    "    output_types=tf.float32 ,\n",
    "    output_shapes=tf.TensorShape((batch_size, ) + image_size)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data[0].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(inputs_shape, Iterable):\n",
    "    _outputs_shape = np.prod(inputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_outputs_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lays = [tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=latents_dim)]\n",
    "\n",
    "dec_lays = [tf.keras.layers.Dense(units=latents_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=_outputs_shape),\n",
    "            tf.keras.layers.Reshape(inputs_shape)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'AE_Dense_reconst_ell'\n",
    "experiments_dir='experiments'+sep_local+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.autoencoding_basic.autoencoders.autoencoder import autoencoder as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape=image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latents_dim,\n",
    "        'layers': enc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latents_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(experiments_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_if_not_exist(_restore)\n",
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to restore trained model, set filepath=_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae = AE( \n",
    "    name=model_name,\n",
    "    latents_dim=latents_dim,\n",
    "    batch_size=batch_size,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae.compile(metrics=None)\n",
    "ae.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore,save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.join(experiments_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, ae.name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(experiments_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latents_shape=latents_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae.fit(\n",
    "    x=train_ds,\n",
    "    input_kw=None,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=int(1e6), \n",
    "    verbose=2,\n",
    "    callbacks=[ es, ms, csv_log, sg],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_mean, is_sigma = inception_score(ae, tolerance_threshold=1e-6, max_iteration=1000)\n",
    "print(f'inception_score mean: {is_mean}, sigma: {is_sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis_score = frechet_inception_distance(ae, training_generator, tolerance_threshold=1e-6, max_iteration=10, batch_size=32)\n",
    "print(f'frechet inception distance: {fis_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.perceptual_path_length import perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_mean_score = perceptual_path_length_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=500, batch_size=32)\n",
    "print(f'perceptual path length score: {ppl_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_precision_score = precision_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=500)\n",
    "print(f'precision score: {_precision_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_recall_score = recall_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=500)\n",
    "print(f'recall score: {_recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import reconstruct_from_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_like_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'random_synthetic_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
