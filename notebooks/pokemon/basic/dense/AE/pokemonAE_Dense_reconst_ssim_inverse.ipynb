{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "\n",
    "import sys\n",
    "sys.path.append('..'+sep_local+'..')\n",
    "print(sep_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalid\\Documents\\projects\\Generative_Models\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat data/.pokemon/pokemon.tar.part* > data/.pokemon/pokemon.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -xvf data/.pokemon/pokemon_combined.tar --directory data/.pokemon/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from training.generators.from_lmdb.lmdb_image_generator import get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='pokemon'\n",
    "inputs_shape= image_shape=(100, 100, 3)\n",
    "batch_size = 10\n",
    "latents_dim = 100\n",
    "intermediate_dim = 50\n",
    "lmdb_dir = 'data/.pokemon/Pokemon_LMDB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformation.lmdb_transformer import LmdbTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEBUG    | Looking for images in '_training'\n",
      "  DEBUG    | Looking for images in '_training'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | No files found\n",
      "  WARNING  | No files found\n",
      "C:\\Users\\Khalid\\Documents\\projects\\Generative_Models\\transformation\\file_image_generator.py:51: UserWarning: No files found\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEBUG    | Looking for images in '_validation'\n",
      "  DEBUG    | Looking for images in '_validation'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | No files found\n",
      "  WARNING  | No files found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Iterator training Number of images 591\n",
      "Initializing Iterator validation Number of images 218\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = get_generators(\n",
    "        lmdb_dir=lmdb_dir,\n",
    "        batch_size=batch_size,\n",
    "        episode_len=None,\n",
    "        episode_shift=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "_instance_scale=1.0\n",
    "for data in val_generator:\n",
    "    print(data['images'].numpy().max())\n",
    "    break\n",
    "    #print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 100, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['images'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'label'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable\n",
    "if isinstance(inputs_shape, Iterable):\n",
    "    flat_outputs_shape = np.prod(inputs_shape)\n",
    "flat_outputs_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lays = [tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=latents_dim)]\n",
    "\n",
    "dec_lays = [tf.keras.layers.Dense(units=latents_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units= latents_dim*intermediate_dim//3 , activation='relu'),\n",
    "            tf.keras.layers.Dense(units= latents_dim*intermediate_dim//3 , activation='relu'),\n",
    "            tf.keras.layers.Dense(units= latents_dim*intermediate_dim//3 , activation='relu'),\n",
    "\n",
    "            tf.keras.layers.Dense(units=flat_outputs_shape),\n",
    "            tf.keras.layers.Reshape(inputs_shape)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'AE_Dense_reconst_ssim_inverse'\n",
    "experiments_dir='experiments'+sep_local+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.autoencoding_basic.autoencoders.autoencoder import autoencoder as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latents_dim,\n",
    "        'layers': enc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latents_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(experiments_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonAE_Dense_reconst_ssim_inverse\\\\var_save_dir'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exist(_restore)\n",
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to restore trained model, set filepath=_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inference\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100, 100, 50)      200       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 100, 50)      2550      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 500000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               50000100  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 50,003,250\n",
      "Trainable params: 50,003,050\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n",
      "  WARNING  | None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generative\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1666)              168266    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1666)              2777222   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1666)              2777222   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30000)             50010000  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 100, 3)       12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 100, 100, 3)       0         \n",
      "=================================================================\n",
      "Total params: 55,742,822\n",
      "Trainable params: 55,742,816\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n",
      "  WARNING  | None\n"
     ]
    }
   ],
   "source": [
    "ae = AE( \n",
    "    name=model_name,\n",
    "    latents_dim=latents_dim,\n",
    "    batch_size=batch_size,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.quantitive_metrics.structural_similarity import prepare_ssim_multiscale\n",
    "\n",
    "#from statistical.losses_utilities import similarty_to_distance\n",
    "from statistical.ae_losses import expected_loglikelihood_with_lower_bound as ellwlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_to_distance(similarity_fn):\n",
    "    distance_fn = lambda x, y: 0.5*(1-similarity_fn(x,y))\n",
    "    return distance_fn\n",
    "\n",
    "ssim = similarity_to_distance(prepare_ssim_multiscale([ae.batch_size]+ae.get_inputs_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pokemonAE_Dense_reconst_ssim_inverse\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inference (Functional)       (None, 100)               50003250  \n",
      "_________________________________________________________________\n",
      "generative (Functional)      (None, 100, 100, 3)       55742822  \n",
      "_________________________________________________________________\n",
      "tf_op_layer_x_logits (Tensor [(None, 100, 100, 3)]     0         \n",
      "=================================================================\n",
      "Total params: 105,746,072\n",
      "Trainable params: 105,745,866\n",
      "Non-trainable params: 206\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#ae.compile(metrics=None)\n",
    "#ae.compile()\n",
    "ae.compile(loss={'x_logits': lambda x_true, x_logits: ssim(x_true, x_logits)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 100, 100, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=1e-15, \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonAE_Dense_reconst_ssim_inverse\\\\csv_dir\\\\pokemonAE_Dense_reconst_ssim_inverse.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir = os.path.join(experiments_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, ae.name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(experiments_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latents_shape=latents_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:297: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0608s vs `on_train_batch_end` time: 0.1816s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: loss improved from inf to -2.18843, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1574s - loss: -2.1884e+00 - psnr: 11.0665 - total_variation: 95196.5547 - ssim_multiscale: 5.6650 - sharpdiff: 5.2703 - mean_absolute_error: 0.2238 - mean_squared_error: 0.0838 - val_loss: -3.5364e+00 - val_psnr: 17.3230 - val_total_variation: 42071.4258 - val_ssim_multiscale: 8.5737 - val_sharpdiff: 10.4573 - val_mean_absolute_error: 0.1072 - val_mean_squared_error: 0.0194\n",
      "Epoch 2/1000000\n",
      "\n",
      "Epoch 00002: loss improved from -2.18843 to -2.68267, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1562s - loss: -2.6827e+00 - psnr: 12.3160 - total_variation: 97148.0156 - ssim_multiscale: 6.7037 - sharpdiff: 5.3657 - mean_absolute_error: 0.1793 - mean_squared_error: 0.0598 - val_loss: -3.6466e+00 - val_psnr: 18.1953 - val_total_variation: 36923.7344 - val_ssim_multiscale: 8.7485 - val_sharpdiff: 11.3823 - val_mean_absolute_error: 0.1008 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/1000000\n",
      "\n",
      "Epoch 00003: loss improved from -2.68267 to -2.72495, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1551s - loss: -2.7250e+00 - psnr: 12.4241 - total_variation: 95462.8281 - ssim_multiscale: 6.7856 - sharpdiff: 5.4597 - mean_absolute_error: 0.1760 - mean_squared_error: 0.0583 - val_loss: -3.6807e+00 - val_psnr: 18.3580 - val_total_variation: 34804.4141 - val_ssim_multiscale: 8.8025 - val_sharpdiff: 11.8135 - val_mean_absolute_error: 0.1006 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/1000000\n",
      "\n",
      "Epoch 00004: loss improved from -2.72495 to -2.74565, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1558s - loss: -2.7457e+00 - psnr: 12.4739 - total_variation: 94793.7188 - ssim_multiscale: 6.8246 - sharpdiff: 5.4999 - mean_absolute_error: 0.1743 - mean_squared_error: 0.0576 - val_loss: -3.6901e+00 - val_psnr: 18.3297 - val_total_variation: 33023.4375 - val_ssim_multiscale: 8.7747 - val_sharpdiff: 12.0883 - val_mean_absolute_error: 0.1043 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/1000000\n",
      "\n",
      "Epoch 00005: loss improved from -2.74565 to -2.75769, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1544s - loss: -2.7577e+00 - psnr: 12.5028 - total_variation: 94344.2891 - ssim_multiscale: 6.8463 - sharpdiff: 5.5263 - mean_absolute_error: 0.1734 - mean_squared_error: 0.0573 - val_loss: -3.7128e+00 - val_psnr: 18.4867 - val_total_variation: 32402.4766 - val_ssim_multiscale: 8.8136 - val_sharpdiff: 12.2695 - val_mean_absolute_error: 0.1027 - val_mean_squared_error: 0.0148\n",
      "Epoch 6/1000000\n",
      "\n",
      "Epoch 00006: loss improved from -2.75769 to -2.76762, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1535s - loss: -2.7676e+00 - psnr: 12.5267 - total_variation: 94081.6797 - ssim_multiscale: 6.8638 - sharpdiff: 5.5427 - mean_absolute_error: 0.1726 - mean_squared_error: 0.0569 - val_loss: -3.6908e+00 - val_psnr: 18.1958 - val_total_variation: 31834.6172 - val_ssim_multiscale: 8.7438 - val_sharpdiff: 12.3192 - val_mean_absolute_error: 0.1074 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/1000000\n",
      "\n",
      "Epoch 00007: loss improved from -2.76762 to -2.77411, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1530s - loss: -2.7741e+00 - psnr: 12.5436 - total_variation: 93827.0391 - ssim_multiscale: 6.8749 - sharpdiff: 5.5571 - mean_absolute_error: 0.1721 - mean_squared_error: 0.0567 - val_loss: -3.6598e+00 - val_psnr: 17.7786 - val_total_variation: 29932.3516 - val_ssim_multiscale: 8.6166 - val_sharpdiff: 12.3529 - val_mean_absolute_error: 0.1170 - val_mean_squared_error: 0.0176\n",
      "Epoch 8/1000000\n",
      "\n",
      "Epoch 00008: loss improved from -2.77411 to -2.78056, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1530s - loss: -2.7806e+00 - psnr: 12.5594 - total_variation: 93660.7344 - ssim_multiscale: 6.8858 - sharpdiff: 5.5673 - mean_absolute_error: 0.1716 - mean_squared_error: 0.0565 - val_loss: -3.6029e+00 - val_psnr: 17.0333 - val_total_variation: 26899.9512 - val_ssim_multiscale: 8.4394 - val_sharpdiff: 12.2599 - val_mean_absolute_error: 0.1293 - val_mean_squared_error: 0.0206\n",
      "Epoch 9/1000000\n",
      "\n",
      "Epoch 00009: loss improved from -2.78056 to -2.78559, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1531s - loss: -2.7856e+00 - psnr: 12.5726 - total_variation: 93513.3828 - ssim_multiscale: 6.8943 - sharpdiff: 5.5766 - mean_absolute_error: 0.1712 - mean_squared_error: 0.0563 - val_loss: -3.3749e+00 - val_psnr: 15.3336 - val_total_variation: 21571.6016 - val_ssim_multiscale: 7.9126 - val_sharpdiff: 11.9416 - val_mean_absolute_error: 0.1592 - val_mean_squared_error: 0.0303\n",
      "Epoch 10/1000000\n",
      "\n",
      "Epoch 00010: loss improved from -2.78559 to -2.78880, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1530s - loss: -2.7888e+00 - psnr: 12.5761 - total_variation: 93334.0938 - ssim_multiscale: 6.8993 - sharpdiff: 5.5852 - mean_absolute_error: 0.1711 - mean_squared_error: 0.0563 - val_loss: -3.2373e+00 - val_psnr: 14.6519 - val_total_variation: 19277.2891 - val_ssim_multiscale: 7.6188 - val_sharpdiff: 11.8291 - val_mean_absolute_error: 0.1731 - val_mean_squared_error: 0.0353\n",
      "Epoch 11/1000000\n",
      "\n",
      "Epoch 00011: loss improved from -2.78880 to -2.79215, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1532s - loss: -2.7922e+00 - psnr: 12.5851 - total_variation: 93215.3359 - ssim_multiscale: 6.9056 - sharpdiff: 5.5922 - mean_absolute_error: 0.1708 - mean_squared_error: 0.0562 - val_loss: -3.1310e+00 - val_psnr: 14.2458 - val_total_variation: 17859.7500 - val_ssim_multiscale: 7.3966 - val_sharpdiff: 11.7550 - val_mean_absolute_error: 0.1820 - val_mean_squared_error: 0.0388\n",
      "Epoch 12/1000000\n",
      "\n",
      "Epoch 00012: loss improved from -2.79215 to -2.79325, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1530s - loss: -2.7932e+00 - psnr: 12.5854 - total_variation: 93107.6641 - ssim_multiscale: 6.9073 - sharpdiff: 5.5981 - mean_absolute_error: 0.1708 - mean_squared_error: 0.0562 - val_loss: -3.0230e+00 - val_psnr: 13.8369 - val_total_variation: 16440.7539 - val_ssim_multiscale: 7.1711 - val_sharpdiff: 11.6949 - val_mean_absolute_error: 0.1915 - val_mean_squared_error: 0.0426\n",
      "Epoch 13/1000000\n",
      "\n",
      "Epoch 00013: loss improved from -2.79325 to -2.79486, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1530s - loss: -2.7949e+00 - psnr: 12.5874 - total_variation: 92979.9688 - ssim_multiscale: 6.9103 - sharpdiff: 5.6054 - mean_absolute_error: 0.1708 - mean_squared_error: 0.0562 - val_loss: -3.0674e+00 - val_psnr: 14.0151 - val_total_variation: 16688.2129 - val_ssim_multiscale: 7.2645 - val_sharpdiff: 11.7428 - val_mean_absolute_error: 0.1873 - val_mean_squared_error: 0.0408\n",
      "Epoch 14/1000000\n",
      "\n",
      "Epoch 00014: loss improved from -2.79486 to -2.79647, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n",
      "5000/5000 - 1531s - loss: -2.7965e+00 - psnr: 12.5868 - total_variation: 92860.5938 - ssim_multiscale: 6.9132 - sharpdiff: 5.6115 - mean_absolute_error: 0.1708 - mean_squared_error: 0.0562 - val_loss: -3.0942e+00 - val_psnr: 14.1087 - val_total_variation: 16813.6328 - val_ssim_multiscale: 7.3205 - val_sharpdiff: 11.7792 - val_mean_absolute_error: 0.1851 - val_mean_squared_error: 0.0399\n",
      "Epoch 15/1000000\n",
      "\n",
      "Epoch 00015: loss improved from -2.79647 to -2.79746, saving model to experiments\\pokemonAE_Dense_reconst_ssim_inverse\\var_save_dir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 - 1531s - loss: -2.7975e+00 - psnr: 12.5889 - total_variation: 92818.5781 - ssim_multiscale: 6.9151 - sharpdiff: 5.6143 - mean_absolute_error: 0.1708 - mean_squared_error: 0.0561 - val_loss: -3.0288e+00 - val_psnr: 13.8637 - val_total_variation: 15999.5869 - val_ssim_multiscale: 7.1838 - val_sharpdiff: 11.7456 - val_mean_absolute_error: 0.1907 - val_mean_squared_error: 0.0422\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bd2973108>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit(\n",
    "    x=train_generator,\n",
    "    input_kw='images',\n",
    "    steps_per_epoch=int(5e3),\n",
    "    epochs=int(1e6), \n",
    "    verbose=2,\n",
    "    callbacks=[es, ms, csv_log, sg],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=int(1e4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the inception_score mean ...\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 75, 3) for input Tensor(\"input_1:0\", shape=(None, 75, 75, 3), dtype=float32), but it was called on an input with incompatible shape (None, 100, 100, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [52:49, 31.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the inception_score sigma ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:780: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "0it [00:00, ?it/s]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\core.py:119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return func(*args2)\n",
      "1it [00:31, 31.10s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "2it [01:02, 31.09s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "3it [01:33, 31.09s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "4it [02:04, 31.11s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "5it [02:36, 31.28s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "6it [03:07, 31.44s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "7it [03:39, 31.54s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "8it [04:10, 31.46s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "9it [04:42, 31.58s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "10it [05:14, 31.54s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "11it [05:45, 31.51s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "12it [06:17, 31.72s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "13it [06:49, 31.67s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "14it [07:21, 31.67s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "15it [07:52, 31.52s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "16it [08:23, 31.41s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "17it [08:55, 31.57s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "18it [09:27, 31.70s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "19it [09:59, 31.81s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "20it [10:31, 31.89s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "21it [11:02, 31.75s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "22it [11:34, 31.80s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "23it [12:06, 31.77s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "24it [12:38, 31.70s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "25it [13:09, 31.68s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "26it [13:41, 31.61s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "27it [14:12, 31.57s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "28it [14:44, 31.54s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "29it [15:16, 31.75s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "30it [15:48, 32.01s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "31it [16:21, 32.12s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "32it [16:53, 32.13s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "33it [17:25, 32.06s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "34it [17:57, 31.94s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "35it [18:28, 31.91s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "36it [19:01, 31.97s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "37it [19:33, 32.10s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "38it [20:06, 32.25s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "39it [20:38, 32.47s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "40it [21:10, 32.20s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [21:42, 32.08s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "42it [22:14, 32.04s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "43it [22:45, 31.84s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "44it [23:17, 31.95s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "45it [23:50, 32.03s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "46it [24:22, 31.99s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "47it [24:54, 32.09s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "48it [25:26, 32.22s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "49it [25:59, 32.32s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "50it [26:31, 32.32s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "51it [27:03, 32.30s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "52it [27:36, 32.47s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "53it [28:09, 32.60s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "54it [28:41, 32.37s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "55it [29:13, 32.17s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "56it [29:45, 32.26s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "57it [30:18, 32.26s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "58it [30:49, 32.17s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "59it [31:21, 32.11s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "60it [31:54, 32.13s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "61it [32:25, 31.90s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "62it [32:57, 31.85s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "63it [33:29, 31.85s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "64it [34:00, 31.79s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "65it [34:32, 31.66s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "66it [35:03, 31.61s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "67it [35:34, 31.46s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "68it [36:05, 31.36s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "69it [36:37, 31.31s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "70it [37:08, 31.25s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "71it [37:39, 31.21s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "72it [38:10, 31.16s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "73it [38:41, 31.13s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "74it [39:12, 31.11s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "75it [39:43, 31.08s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "76it [40:14, 31.07s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "77it [40:45, 31.10s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "78it [41:16, 31.09s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "79it [41:47, 31.08s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "80it [42:18, 31.06s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "81it [42:49, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "82it [43:20, 31.04s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [43:51, 31.04s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "84it [44:22, 31.04s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "85it [44:53, 31.03s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "86it [45:24, 31.02s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "87it [45:55, 31.02s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "88it [46:26, 31.02s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "89it [46:57, 31.02s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "90it [47:28, 31.02s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "91it [48:00, 31.04s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "92it [48:31, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "93it [49:02, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "94it [49:33, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "95it [50:04, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "96it [50:35, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "97it [51:06, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "98it [51:37, 31.05s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "99it [52:08, 31.19s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\core.py:3923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = function(*args, **kwargs)\n",
      "100it [52:39, 31.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_score mean: dask.array<mean_agg-aggregate, shape=(1,), dtype=float64, chunksize=(1,), chunktype=numpy.ndarray>, sigma: dask.array<getitem, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "is_mean, is_sigma = inception_score(ae, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'inception_score mean: {is_mean}, sigma: {is_sigma}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.25042361e+165])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_mean.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-281ca4026dd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfis_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrechet_inception_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'frechet inception distance: {fis_score}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "fis_score = frechet_inception_distance(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100, batch_size=32)\n",
    "print(f'frechet inception distance: {fis_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.perceptual_path_length import perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_mean_score = perceptual_path_length_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100, batch_size=32)\n",
    "print(f'perceptual path length score: {ppl_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_precision_score = precision_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'precision score: {_precision_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_recall_score = recall_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'recall score: {_recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import reconstruct_from_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_like_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    for data in train_generator:\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'random_synthetic_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_randomly(ae, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import interpolate_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'interpolate_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "interpolate_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
