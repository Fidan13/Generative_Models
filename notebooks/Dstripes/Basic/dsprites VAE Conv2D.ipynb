{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..\\\\..\\\\..\\\\..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'dsprites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='dsprites',\n",
      "    version=0.1.0,\n",
      "    description='dSprites is a dataset of 2D shapes procedurally generated from 6 ground truth\n",
      "independent latent factors. These factors are *color*, *shape*, *scale*,\n",
      "*rotation*, *x* and *y* positions of a sprite.\n",
      "\n",
      "All possible combinations of these latents are present exactly once,\n",
      "generating N = 737280 total images.\n",
      "\n",
      "### Latent factor values\n",
      "\n",
      "*   Color: white\n",
      "*   Shape: square, ellipse, heart\n",
      "*   Scale: 6 values linearly spaced in [0.5, 1]\n",
      "*   Orientation: 40 values in [0, 2 pi]\n",
      "*   Position X: 32 values in [0, 1]\n",
      "*   Position Y: 32 values in [0, 1]\n",
      "\n",
      "We varied one latent at a time (starting from Position Y, then Position X, etc),\n",
      "and sequentially stored the images in fixed order.\n",
      "Hence the order along the first dimension is fixed and allows you to map back to\n",
      "the value of the latents corresponding to that image.\n",
      "\n",
      "We chose the latents values deliberately to have the smallest step changes\n",
      "while ensuring that all pixel outputs were different. No noise was added.\n",
      "',\n",
      "    urls=['https://github.com/deepmind/dsprites-dataset'],\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(64, 64, 1), dtype=tf.uint8),\n",
      "        'label_orientation': ClassLabel(shape=(), dtype=tf.int64, num_classes=40),\n",
      "        'label_scale': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),\n",
      "        'label_shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "        'label_x_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'label_y_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'value_orientation': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_scale': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_shape': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_x_position': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_y_position': Tensor(shape=[], dtype=tf.float32),\n",
      "    }),\n",
      "    total_num_examples=737280,\n",
      "    splits={\n",
      "        'train': 737280,\n",
      "    },\n",
      "    supervised_keys=None,\n",
      "    citation=\"\"\"@misc{dsprites17,\n",
      "    author = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},\n",
      "    title = {dSprites: Disentanglement testing Sprites dataset},\n",
      "    howpublished= {https://github.com/deepmind/dsprites-dataset/},\n",
      "    year = \"2017\",\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "info = tfds.builder(dataset_name).info\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dim = 20\n",
    "inputs_shape=(64, 64, 1) # image shape\n",
    "batch_size = 100\n",
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = 600\n",
    "TEST_BUF = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# Construct a tf.data.Dataset\n",
    "train_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TRAIN_BUF).batch(batch_size)\n",
    "try:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TEST).shuffle(TEST_BUF).batch(batch_size)\n",
    "except:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TEST_BUF).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data['image'][0].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lays2 = [\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latent_dim)\n",
    "]\n",
    "\n",
    "enc_lays3 = [\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latent_dim)\n",
    "]\n",
    "\n",
    "dec_lays2 = [\n",
    "    tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    \n",
    "    # No activation\n",
    "    tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_mean_lays = [tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu')]\n",
    "\n",
    "enc_var_lays = [tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu')]\n",
    "\n",
    "dec_lays = [tf.keras.layers.Dense(units=2*intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=2*intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=2*intermediate_dim, activation='relu')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.data_and_files.file_utils import make_random_string\n",
    "#from time import gmtime, strftime\n",
    "\n",
    "#model_name = 'AE_' + make_random_string(5) + strftime(\"%a_%d_%b_%Y_%H_%M\", gmtime())\n",
    "#print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'VAE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoding_dir='..\\\\..\\\\..\\\\..\\\\recoding\\\\'+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\..\\\\..\\\\recoding\\\\dspritesVAE\\\\dspritesVAE'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(recoding_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ef2a77ca3d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoencoders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAE\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'training'"
     ]
    }
   ],
   "source": [
    "from training.autoencoders.VAE import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'encoder_mean', \n",
    "        'inputs_shape': inputs_shape,\n",
    "        'outputs_shape': latent_dim,\n",
    "        'layers': enc_lays2\n",
    "    }\n",
    "    ,\n",
    "    \n",
    "     {\n",
    "        'name': 'encoder_logvar', \n",
    "        'inputs_shape': inputs_shape,\n",
    "        'outputs_shape': latent_dim,\n",
    "        'layers': enc_lays3\n",
    "    }\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape': latent_dim,\n",
    "        'outputs_shape': inputs_shape,\n",
    "        'layers': dec_lays2\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(recoding_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE( \n",
    "    model_name=model_name, \n",
    "    inputs_shape=inputs_shape, \n",
    "    outputs_shape = inputs_shape,\n",
    "    latent_dim= latent_dim, \n",
    "    variables_params=variables_params, \n",
    "    restore=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_generated = 36\n",
    "random_latent = np.random.normal(size=[n_generated, latent_dim])\n",
    "#np.save(file='random_latent.npy', arr=random_latent)\n",
    "#random_latent = tf.constant(np.load(file='..\\\\data\\\\random_latent.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e28298cc2eb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m vae.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minstance_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vae' is not defined"
     ]
    }
   ],
   "source": [
    "vae.fit(\n",
    "    train_dataset=train_ds, \n",
    "    test_dataset=test_ds,\n",
    "    instance_names=['image'],\n",
    "    epochs=500,\n",
    "    learning_rate=1e-3,\n",
    "    random_latent=random_latent,\n",
    "    recoding_dir=recoding_dir,\n",
    "    gray_plot=True,\n",
    "    generate_epoch=5,\n",
    "    save_epoch=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Cells below are old Ground truth Metrics measurements \n",
    "#now they are logged and saved with losses in the same manner during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '..\\\\data\\\\gt_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.gt_load.datasets import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = load(dataset_name='dsprites_full', dataset_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_func(x):\n",
    "    z, mean, logvar = vae.encode(x)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.unsupervised_metrics.compute_metrics import compute_unsupervised_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_scores = compute_unsupervised_metrics(\n",
    "    ground_truth_data=eval_dataset, \n",
    "    representation_function=rep_func, \n",
    "    random_state=np.random.RandomState(0),\n",
    "    num_train=10000,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.supervised_metrics.compute_metrics import compute_supervised_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scores = compute_supervised_metrics(\n",
    "    ground_truth_data=eval_dataset, \n",
    "    representation_function=rep_func, \n",
    "    random_state=np.random.RandomState(0),\n",
    "    num_train=10000,\n",
    "    num_test=2000,\n",
    "    continuous_factors=False,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
