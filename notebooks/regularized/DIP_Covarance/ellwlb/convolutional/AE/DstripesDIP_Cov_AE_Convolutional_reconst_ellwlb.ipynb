{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_KERAS=1\n",
      "\\\n"
     ]
    }
   ],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "\n",
    "import sys\n",
    "sys.path.append('..'+sep_local+'..')\n",
    "print(sep_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalid\\Documents\\projects\\Generative_Models\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='dsprites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape= image_size=(64, 64, 1)\n",
    "batch_size = 32\n",
    "latents_dim = 32\n",
    "intermediate_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='dsprites',\n",
      "    version=0.1.0,\n",
      "    description='dSprites is a dataset of 2D shapes procedurally generated from 6 ground truth\n",
      "independent latent factors. These factors are *color*, *shape*, *scale*,\n",
      "*rotation*, *x* and *y* positions of a sprite.\n",
      "\n",
      "All possible combinations of these latents are present exactly once,\n",
      "generating N = 737280 total images.\n",
      "\n",
      "### Latent factor values\n",
      "\n",
      "*   Color: white\n",
      "*   Shape: square, ellipse, heart\n",
      "*   Scale: 6 values linearly spaced in [0.5, 1]\n",
      "*   Orientation: 40 values in [0, 2 pi]\n",
      "*   Position X: 32 values in [0, 1]\n",
      "*   Position Y: 32 values in [0, 1]\n",
      "\n",
      "We varied one latent at a time (starting from Position Y, then Position X, etc),\n",
      "and sequentially stored the images in fixed order.\n",
      "Hence the order along the first dimension is fixed and allows you to map back to\n",
      "the value of the latents corresponding to that image.\n",
      "\n",
      "We chose the latents values deliberately to have the smallest step changes\n",
      "while ensuring that all pixel outputs were different. No noise was added.\n",
      "',\n",
      "    urls=['https://github.com/deepmind/dsprites-dataset'],\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(64, 64, 1), dtype=tf.uint8),\n",
      "        'label_orientation': ClassLabel(shape=(), dtype=tf.int64, num_classes=40),\n",
      "        'label_scale': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),\n",
      "        'label_shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "        'label_x_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'label_y_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'value_orientation': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_scale': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_shape': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_x_position': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_y_position': Tensor(shape=[], dtype=tf.float32),\n",
      "    }),\n",
      "    total_num_examples=737280,\n",
      "    splits={\n",
      "        'train': 737280,\n",
      "    },\n",
      "    supervised_keys=None,\n",
      "    citation=\"\"\"@misc{dsprites17,\n",
      "    author = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},\n",
      "    title = {dSprites: Disentanglement testing Sprites dataset},\n",
      "    howpublished= {https://github.com/deepmind/dsprites-dataset/},\n",
      "    year = \"2017\",\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "info = tfds.builder(dataset_name).info\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BUF = 600\n",
    "TEST_BUF = 100\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "# Construct a tf.data.Dataset\n",
    "train_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TRAIN_BUF).batch(batch_size)\n",
    "try:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TEST).shuffle(TEST_BUF).batch(batch_size)\n",
    "except:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TRAIN_BUF).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data['image'].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_instance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(inputs_shape, Iterable):\n",
    "    _outputs_shape = np.prod(inputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_outputs_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=20\n",
    "c=16\n",
    "enc_lays = [\n",
    "    tf.keras.layers.Conv2D(filters=units, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=units*9, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latents_dim)\n",
    "]\n",
    "\n",
    "dec_lays = [\n",
    "    tf.keras.layers.Dense(units=c*c*units, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Reshape(target_shape=(c , c, units)),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=units, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=units*3, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    \n",
    "    # No activation\n",
    "    tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'DIP_Cov_AE_Convolutional_reconst_ellwlb'\n",
    "experiments_dir='experiments'+sep_local+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.regularized.disentangled_inferred_prior.DIP_Covariance_AE import DIP_Covariance_AE as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape=image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latents_dim,\n",
    "        'layers': enc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latents_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(experiments_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb\\\\var_save_dir'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exist(_restore)\n",
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to restore trained model, set filepath=_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inference\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 31, 31, 20)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 180)       32580     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40500)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1296032   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 1,328,940\n",
      "Trainable params: 1,328,876\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generative\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5120)              168960    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 20)        3620      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 64, 64, 60)        10860     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 1)         541       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 1)         4         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 64, 64, 1)         0         \n",
      "=================================================================\n",
      "Total params: 183,985\n",
      "Trainable params: 183,983\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    }
   ],
   "source": [
    "ae = AE( \n",
    "    name=model_name,\n",
    "    latents_dim=latents_dim,\n",
    "    batch_size=batch_size,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inference_inputs (InputLayer)   [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inference (Model)               (None, 32)           1328940     inference_inputs[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 32, 1)]      0           inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 32)]      0           inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(32,)]              0           inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None, 32, 32)]     0           tf_op_layer_ExpandDims[0][0]     \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(32, 1)]            0           tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(1, 32)]            0           tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(32, 32)]           0           tf_op_layer_mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(32, 32)]           0           tf_op_layer_ExpandDims_2[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(32, 32)]           0           tf_op_layer_Mean[0][0]           \n",
      "                                                                 tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_diag_part (TensorFl [(32,)]              0           tf_op_layer_Sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_diag (TensorFlowOpL [(32, 32)]           0           tf_op_layer_diag_part[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_1 (TensorFlowOp [(32, 32)]           0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_diag[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_2 (TensorFlowOp [(32,)]              0           tf_op_layer_diag_part[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow (TensorFlowOpLa [(32, 32)]           0           tf_op_layer_sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow_1 (TensorFlowOp [(32,)]              0           tf_op_layer_sub_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_2 (TensorFlowOp [(32, 32)]           0           tf_op_layer_pow[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_3 (TensorFlowOp [(32,)]              0           tf_op_layer_pow_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add (TensorFlowOpLa [(32, 32)]           0           tf_op_layer_mul_2[0][0]          \n",
      "                                                                 tf_op_layer_mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "generative (Model)              (None, 64, 64, 1)    183985      inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_covariance_regulari [(32, 32)]           0           tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_x_logits (TensorFlo [(None, 64, 64, 1)]  0           generative[1][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,512,925\n",
      "Trainable params: 1,512,859\n",
      "Non-trainable params: 66\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#ae.compile(metrics=None)\n",
    "ae.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore,save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb\\\\csv_dir\\\\dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir = os.path.join(experiments_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, ae.name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(experiments_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latents_shape=latents_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "#DATA_DOWN_PATH = '..'+sep_local+'..'+sep_local+'..'+sep_local+'data'\n",
    "DATA_DOWN_PATH = os.getcwd() + sep_local+'data'\n",
    "Script_dir = os.getcwd() + sep_local+'data'+sep_local+'download_gt_data.sh'\n",
    "# Script call to download \"dsprites_full\" dataset_name \n",
    "!/bin/bash $Script_dir -f $DATA_DOWN_PATH -d $dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH C:\\Users\\Khalid\\Documents\\projects\\Generative_Models\\data\\.gt_datasets\n"
     ]
    }
   ],
   "source": [
    "from os.path import abspath\n",
    "\n",
    "from data.gt_load.datasets import load\n",
    "DATA_PATH = DATA_DOWN_PATH +sep_local+'.gt_datasets'\n",
    "absolute = abspath(DATA_PATH)\n",
    "print(\"DATA_PATH\",absolute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_dataset = load(dataset_name='dsprites_full', dataset_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.callbacks.disentangle_supervied import DisentanglementSuperviedMetrics\n",
    "from training.callbacks.disentangle_unsupervied import DisentanglementUnsuperviedMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gts_mertics = DisentanglementSuperviedMetrics(            \n",
    "#    ground_truth_data=eval_dataset,\n",
    "#    representation_fn=lambda x: ae.encode(x),\n",
    "#    random_state=np.random.RandomState(0),\n",
    "#    file_Name=gts_csv,\n",
    "#    num_train=10000,\n",
    "#    num_test=100,\n",
    "#    batch_size=batch_size,\n",
    "#    continuous_factors=False,\n",
    "#    gt_freq=10\n",
    "#)\n",
    "#gtu_mertics = DisentanglementUnsuperviedMetrics(            \n",
    "#    ground_truth_data=eval_dataset,\n",
    "#    representation_fn=lambda x: ae.encode(x),\n",
    "#    random_state=np.random.RandomState(0),\n",
    "#    file_Name=gtu_csv,\n",
    "#    num_train=10000,\n",
    "#    num_test=100,\n",
    "#    batch_size=batch_size,\n",
    "#    gt_freq=10\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 40s - loss: 2866.1460 - covariance_regularized_loss: 17.0910 - x_logits_loss: 2849.0547 - x_logits_psnr: 5.9996 - x_logits_ssim: 0.0220 - x_logits_sharpdiff: 9.9898 - x_logits_mean_absolute_error: 0.5001 - x_logits_mean_squared_error: 0.251 - ETA: 10s - loss: 1827.4673 - covariance_regularized_loss: 16.6053 - x_logits_loss: 1810.8353 - x_logits_psnr: 8.8381 - x_logits_ssim: 0.0073 - x_logits_sharpdiff: 6.3940 - x_logits_mean_absolute_error: 0.2961 - x_logits_mean_squared_error: 0.147 - ETA: 4s - loss: 1662.3611 - covariance_regularized_loss: 11.7741 - x_logits_loss: 1650.5374 - x_logits_psnr: 9.3771 - x_logits_ssim: 0.0044 - x_logits_sharpdiff: 5.5471 - x_logits_mean_absolute_error: 0.2445 - x_logits_mean_squared_error: 0.127 - ETA: 2s - loss: 1574.8096 - covariance_regularized_loss: 9.0957 - x_logits_loss: 1565.6521 - x_logits_psnr: 9.6545 - x_logits_ssim: 0.0031 - x_logits_sharpdiff: 5.1893 - x_logits_mean_absolute_error: 0.2208 - x_logits_mean_squared_error: 0.1177 - ETA: 0s - loss: 1522.6552 - covariance_regularized_loss: 7.5668 - x_logits_loss: 1515.0199 - x_logits_psnr: 9.8158 - x_logits_ssim: 0.0024 - x_logits_sharpdiff: 4.9870 - x_logits_mean_absolute_error: 0.2074 - x_logits_mean_squared_error: 0.112 - 6s 626ms/step - loss: 1506.7424 - covariance_regularized_loss: 7.0142 - x_logits_loss: 1499.6573 - x_logits_psnr: 9.8669 - x_logits_ssim: 0.0022 - x_logits_sharpdiff: 4.9155 - x_logits_mean_absolute_error: 0.2029 - x_logits_mean_squared_error: 0.1103 - val_loss: 768.3789 - val_covariance_regularized_loss: 24.8639 - val_x_logits_loss: 743.4484 - val_x_logits_psnr: 14.3005 - val_x_logits_ssim: -0.0042 - val_x_logits_sharpdiff: 17.8959 - val_x_logits_mean_absolute_error: 0.0683 - val_x_logits_mean_squared_error: 0.0415\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1405.0778 - covariance_regularized_loss: 2.1092 - x_logits_loss: 1402.8766 - x_logits_psnr: 10.2326 - x_logits_ssim: 8.8734e-05 - x_logits_sharpdiff: 4.2572 - x_logits_mean_absolute_error: 0.1645 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1362.4825 - covariance_regularized_loss: 1.8782 - x_logits_loss: 1360.5123 - x_logits_psnr: 10.3295 - x_logits_ssim: 4.7411e-05 - x_logits_sharpdiff: 4.2721 - x_logits_mean_absolute_error: 0.1621 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1374.2950 - covariance_regularized_loss: 1.8552 - x_logits_loss: 1372.3477 - x_logits_psnr: 10.3053 - x_logits_ssim: 1.5441e-05 - x_logits_sharpdiff: 4.2689 - x_logits_mean_absolute_error: 0.1626 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1358.8358 - covariance_regularized_loss: 1.8189 - x_logits_loss: 1356.9247 - x_logits_psnr: 10.3346 - x_logits_ssim: 2.8726e-05 - x_logits_sharpdiff: 4.2648 - x_logits_mean_absolute_error: 0.1620 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1370.0292 - covariance_regularized_loss: 1.7174 - x_logits_loss: 1368.2196 - x_logits_psnr: 10.3059 - x_logits_ssim: 1.6479e-05 - x_logits_sharpdiff: 4.2680 - x_logits_mean_absolute_error: 0.1626 - x_logits_mean_squared_error: 0.09 - 1s 63ms/step - loss: 1363.1182 - covariance_regularized_loss: 1.7637 - x_logits_loss: 1361.2623 - x_logits_psnr: 10.3247 - x_logits_ssim: 2.4297e-05 - x_logits_sharpdiff: 4.2692 - x_logits_mean_absolute_error: 0.1622 - x_logits_mean_squared_error: 0.0940 - val_loss: 760.4895 - val_covariance_regularized_loss: 24.7740 - val_x_logits_loss: 735.6489 - val_x_logits_psnr: 14.3676 - val_x_logits_ssim: -0.0041 - val_x_logits_sharpdiff: 17.9224 - val_x_logits_mean_absolute_error: 0.0678 - val_x_logits_mean_squared_error: 0.0410\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1335.8625 - covariance_regularized_loss: 1.5077 - x_logits_loss: 1334.2626 - x_logits_psnr: 10.3703 - x_logits_ssim: -5.3905e-06 - x_logits_sharpdiff: 4.2781 - x_logits_mean_absolute_error: 0.1607 - x_logits_mean_squared_error: 0.092 - ETA: 0s - loss: 1375.4343 - covariance_regularized_loss: 1.6760 - x_logits_loss: 1373.6660 - x_logits_psnr: 10.2783 - x_logits_ssim: 5.5911e-06 - x_logits_sharpdiff: 4.2663 - x_logits_mean_absolute_error: 0.1629 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1374.3957 - covariance_regularized_loss: 1.5629 - x_logits_loss: 1372.7405 - x_logits_psnr: 10.2917 - x_logits_ssim: 3.5823e-05 - x_logits_sharpdiff: 4.2737 - x_logits_mean_absolute_error: 0.1628 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1372.5530 - covariance_regularized_loss: 1.6437 - x_logits_loss: 1370.8171 - x_logits_psnr: 10.3010 - x_logits_ssim: 2.6572e-05 - x_logits_sharpdiff: 4.2755 - x_logits_mean_absolute_error: 0.1626 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1375.5165 - covariance_regularized_loss: 1.6864 - x_logits_loss: 1373.7379 - x_logits_psnr: 10.2895 - x_logits_ssim: 1.2867e-05 - x_logits_sharpdiff: 4.2740 - x_logits_mean_absolute_error: 0.1629 - x_logits_mean_squared_error: 0.09 - 1s 61ms/step - loss: 1377.0728 - covariance_regularized_loss: 1.6951 - x_logits_loss: 1375.2855 - x_logits_psnr: 10.2866 - x_logits_ssim: 1.2038e-05 - x_logits_sharpdiff: 4.2739 - x_logits_mean_absolute_error: 0.1630 - x_logits_mean_squared_error: 0.0948 - val_loss: 779.9866 - val_covariance_regularized_loss: 24.7065 - val_x_logits_loss: 755.2137 - val_x_logits_psnr: 14.2532 - val_x_logits_ssim: -0.0045 - val_x_logits_sharpdiff: 17.8464 - val_x_logits_mean_absolute_error: 0.0692 - val_x_logits_mean_squared_error: 0.0423\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1441.4574 - covariance_regularized_loss: 2.0807 - x_logits_loss: 1439.2843 - x_logits_psnr: 10.1451 - x_logits_ssim: 1.3963e-04 - x_logits_sharpdiff: 4.2597 - x_logits_mean_absolute_error: 0.1662 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1354.7887 - covariance_regularized_loss: 1.7664 - x_logits_loss: 1352.9299 - x_logits_psnr: 10.3444 - x_logits_ssim: 4.1213e-05 - x_logits_sharpdiff: 4.2734 - x_logits_mean_absolute_error: 0.1620 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1364.0113 - covariance_regularized_loss: 1.9210 - x_logits_loss: 1361.9980 - x_logits_psnr: 10.3235 - x_logits_ssim: -3.4495e-06 - x_logits_sharpdiff: 4.2727 - x_logits_mean_absolute_error: 0.1625 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1372.8758 - covariance_regularized_loss: 1.8733 - x_logits_loss: 1370.9102 - x_logits_psnr: 10.2981 - x_logits_ssim: -8.5780e-06 - x_logits_sharpdiff: 4.2692 - x_logits_mean_absolute_error: 0.1630 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1371.9849 - covariance_regularized_loss: 1.8421 - x_logits_loss: 1370.0504 - x_logits_psnr: 10.2942 - x_logits_ssim: 1.3027e-05 - x_logits_sharpdiff: 4.2665 - x_logits_mean_absolute_error: 0.1631 - x_logits_mean_squared_error: 0.094 - 1s 61ms/step - loss: 1367.5733 - covariance_regularized_loss: 1.8262 - x_logits_loss: 1365.6548 - x_logits_psnr: 10.3037 - x_logits_ssim: 1.5087e-05 - x_logits_sharpdiff: 4.2669 - x_logits_mean_absolute_error: 0.1628 - x_logits_mean_squared_error: 0.0945 - val_loss: 765.6274 - val_covariance_regularized_loss: 24.6789 - val_x_logits_loss: 740.8821 - val_x_logits_psnr: 14.3690 - val_x_logits_ssim: -0.0043 - val_x_logits_sharpdiff: 17.9177 - val_x_logits_mean_absolute_error: 0.0684 - val_x_logits_mean_squared_error: 0.0414\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 1356.7378 - covariance_regularized_loss: 1.8921 - x_logits_loss: 1354.7534 - x_logits_psnr: 10.3344 - x_logits_ssim: 1.3297e-04 - x_logits_sharpdiff: 4.2830 - x_logits_mean_absolute_error: 0.1629 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1354.7952 - covariance_regularized_loss: 1.9528 - x_logits_loss: 1352.7500 - x_logits_psnr: 10.3255 - x_logits_ssim: 5.5680e-05 - x_logits_sharpdiff: 4.2765 - x_logits_mean_absolute_error: 0.1627 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1351.7126 - covariance_regularized_loss: 1.8455 - x_logits_loss: 1349.7747 - x_logits_psnr: 10.3278 - x_logits_ssim: 5.9444e-05 - x_logits_sharpdiff: 4.2696 - x_logits_mean_absolute_error: 0.1625 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1364.6270 - covariance_regularized_loss: 1.9153 - x_logits_loss: 1362.6193 - x_logits_psnr: 10.2926 - x_logits_ssim: 5.1522e-05 - x_logits_sharpdiff: 4.2725 - x_logits_mean_absolute_error: 0.1632 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1362.4105 - covariance_regularized_loss: 2.0542 - x_logits_loss: 1360.2639 - x_logits_psnr: 10.2900 - x_logits_ssim: 3.4539e-05 - x_logits_sharpdiff: 4.2663 - x_logits_mean_absolute_error: 0.1633 - x_logits_mean_squared_error: 0.09 - 1s 61ms/step - loss: 1357.6847 - covariance_regularized_loss: 2.0466 - x_logits_loss: 1355.5457 - x_logits_psnr: 10.2975 - x_logits_ssim: 1.9239e-05 - x_logits_sharpdiff: 4.2689 - x_logits_mean_absolute_error: 0.1631 - x_logits_mean_squared_error: 0.0947 - val_loss: 766.6017 - val_covariance_regularized_loss: 24.4559 - val_x_logits_loss: 742.0798 - val_x_logits_psnr: 14.2826 - val_x_logits_ssim: -0.0042 - val_x_logits_sharpdiff: 17.8821 - val_x_logits_mean_absolute_error: 0.0688 - val_x_logits_mean_squared_error: 0.0415\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1263.2120 - covariance_regularized_loss: 2.0752 - x_logits_loss: 1261.0444 - x_logits_psnr: 10.4796 - x_logits_ssim: -2.3210e-05 - x_logits_sharpdiff: 4.2568 - x_logits_mean_absolute_error: 0.1594 - x_logits_mean_squared_error: 0.090 - ETA: 0s - loss: 1316.0178 - covariance_regularized_loss: 2.3152 - x_logits_loss: 1313.6104 - x_logits_psnr: 10.3456 - x_logits_ssim: -5.8457e-05 - x_logits_sharpdiff: 4.2521 - x_logits_mean_absolute_error: 0.1625 - x_logits_mean_squared_error: 0.093 - ETA: 0s - loss: 1312.4665 - covariance_regularized_loss: 2.3663 - x_logits_loss: 1310.0078 - x_logits_psnr: 10.3554 - x_logits_ssim: -1.0783e-04 - x_logits_sharpdiff: 4.2630 - x_logits_mean_absolute_error: 0.1621 - x_logits_mean_squared_error: 0.093 - ETA: 0s - loss: 1291.9604 - covariance_regularized_loss: 2.5217 - x_logits_loss: 1289.3463 - x_logits_psnr: 10.3937 - x_logits_ssim: -1.4560e-04 - x_logits_sharpdiff: 4.2632 - x_logits_mean_absolute_error: 0.1611 - x_logits_mean_squared_error: 0.092 - ETA: 0s - loss: 1294.6574 - covariance_regularized_loss: 2.8087 - x_logits_loss: 1291.7562 - x_logits_psnr: 10.3752 - x_logits_ssim: -1.7855e-04 - x_logits_sharpdiff: 4.2645 - x_logits_mean_absolute_error: 0.1616 - x_logits_mean_squared_error: 0.092 - 1s 101ms/step - loss: 1294.9606 - covariance_regularized_loss: 3.0350 - x_logits_loss: 1291.8331 - x_logits_psnr: 10.3664 - x_logits_ssim: -1.8670e-04 - x_logits_sharpdiff: 4.2629 - x_logits_mean_absolute_error: 0.1618 - x_logits_mean_squared_error: 0.0930 - val_loss: 777.1217 - val_covariance_regularized_loss: 23.5336 - val_x_logits_loss: 753.5225 - val_x_logits_psnr: 14.2419 - val_x_logits_ssim: -0.0046 - val_x_logits_sharpdiff: 17.8503 - val_x_logits_mean_absolute_error: 0.0700 - val_x_logits_mean_squared_error: 0.0423\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1291.7538 - covariance_regularized_loss: 4.1371 - x_logits_loss: 1287.5237 - x_logits_psnr: 10.2901 - x_logits_ssim: -3.0079e-04 - x_logits_sharpdiff: 4.2703 - x_logits_mean_absolute_error: 0.1630 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1245.8684 - covariance_regularized_loss: 3.8285 - x_logits_loss: 1241.9469 - x_logits_psnr: 10.4067 - x_logits_ssim: -2.9953e-04 - x_logits_sharpdiff: 4.2731 - x_logits_mean_absolute_error: 0.1606 - x_logits_mean_squared_error: 0.091 - ETA: 0s - loss: 1241.7155 - covariance_regularized_loss: 3.9030 - x_logits_loss: 1237.7195 - x_logits_psnr: 10.4079 - x_logits_ssim: -3.7738e-04 - x_logits_sharpdiff: 4.2739 - x_logits_mean_absolute_error: 0.1609 - x_logits_mean_squared_error: 0.092 - ETA: 0s - loss: 1251.5677 - covariance_regularized_loss: 4.2400 - x_logits_loss: 1247.2346 - x_logits_psnr: 10.3711 - x_logits_ssim: -4.7918e-04 - x_logits_sharpdiff: 4.2706 - x_logits_mean_absolute_error: 0.1620 - x_logits_mean_squared_error: 0.092 - ETA: 0s - loss: 1232.3061 - covariance_regularized_loss: 4.4434 - x_logits_loss: 1227.7694 - x_logits_psnr: 10.4066 - x_logits_ssim: -5.7074e-04 - x_logits_sharpdiff: 4.2672 - x_logits_mean_absolute_error: 0.1614 - x_logits_mean_squared_error: 0.092 - 1s 61ms/step - loss: 1226.6403 - covariance_regularized_loss: 4.4344 - x_logits_loss: 1222.1127 - x_logits_psnr: 10.4124 - x_logits_ssim: -6.4603e-04 - x_logits_sharpdiff: 4.2654 - x_logits_mean_absolute_error: 0.1613 - x_logits_mean_squared_error: 0.0919 - val_loss: 750.0998 - val_covariance_regularized_loss: 21.5380 - val_x_logits_loss: 728.4966 - val_x_logits_psnr: 14.4232 - val_x_logits_ssim: -0.0041 - val_x_logits_sharpdiff: 17.9172 - val_x_logits_mean_absolute_error: 0.0688 - val_x_logits_mean_squared_error: 0.0408\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1155.4977 - covariance_regularized_loss: 4.0963 - x_logits_loss: 1151.3076 - x_logits_psnr: 10.4769 - x_logits_ssim: -0.0013 - x_logits_sharpdiff: 4.2543 - x_logits_mean_absolute_error: 0.1602 - x_logits_mean_squared_error: 0.090 - ETA: 0s - loss: 1126.2410 - covariance_regularized_loss: 4.4134 - x_logits_loss: 1121.7339 - x_logits_psnr: 10.5614 - x_logits_ssim: -0.0015 - x_logits_sharpdiff: 4.2403 - x_logits_mean_absolute_error: 0.1592 - x_logits_mean_squared_error: 0.088 - ETA: 0s - loss: 1122.0473 - covariance_regularized_loss: 4.7558 - x_logits_loss: 1117.1978 - x_logits_psnr: 10.5756 - x_logits_ssim: -0.0017 - x_logits_sharpdiff: 4.2378 - x_logits_mean_absolute_error: 0.1591 - x_logits_mean_squared_error: 0.088 - ETA: 0s - loss: 1103.0188 - covariance_regularized_loss: 4.8713 - x_logits_loss: 1098.0536 - x_logits_psnr: 10.6228 - x_logits_ssim: -0.0018 - x_logits_sharpdiff: 4.2390 - x_logits_mean_absolute_error: 0.1584 - x_logits_mean_squared_error: 0.087 - ETA: 0s - loss: 1097.6715 - covariance_regularized_loss: 4.7847 - x_logits_loss: 1092.7927 - x_logits_psnr: 10.6293 - x_logits_ssim: -0.0020 - x_logits_sharpdiff: 4.2365 - x_logits_mean_absolute_error: 0.1585 - x_logits_mean_squared_error: 0.087 - 1s 61ms/step - loss: 1097.7463 - covariance_regularized_loss: 4.8494 - x_logits_loss: 1092.8030 - x_logits_psnr: 10.6269 - x_logits_ssim: -0.0020 - x_logits_sharpdiff: 4.2353 - x_logits_mean_absolute_error: 0.1586 - x_logits_mean_squared_error: 0.0871 - val_loss: 754.2091 - val_covariance_regularized_loss: 18.5262 - val_x_logits_loss: 735.6179 - val_x_logits_psnr: 14.2602 - val_x_logits_ssim: -0.0039 - val_x_logits_sharpdiff: 17.8156 - val_x_logits_mean_absolute_error: 0.0698 - val_x_logits_mean_squared_error: 0.0417\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 993.4290 - covariance_regularized_loss: 3.9581 - x_logits_loss: 989.3763 - x_logits_psnr: 10.9134 - x_logits_ssim: -0.0029 - x_logits_sharpdiff: 4.2407 - x_logits_mean_absolute_error: 0.1539 - x_logits_mean_squared_error: 0.081 - ETA: 0s - loss: 1038.7862 - covariance_regularized_loss: 4.2545 - x_logits_loss: 1034.4371 - x_logits_psnr: 10.7590 - x_logits_ssim: -0.0030 - x_logits_sharpdiff: 4.2227 - x_logits_mean_absolute_error: 0.1572 - x_logits_mean_squared_error: 0.084 - ETA: 0s - loss: 1026.4625 - covariance_regularized_loss: 4.8032 - x_logits_loss: 1021.5646 - x_logits_psnr: 10.7962 - x_logits_ssim: -0.0030 - x_logits_sharpdiff: 4.2335 - x_logits_mean_absolute_error: 0.1564 - x_logits_mean_squared_error: 0.083 - ETA: 0s - loss: 1014.8442 - covariance_regularized_loss: 4.5851 - x_logits_loss: 1010.1642 - x_logits_psnr: 10.8320 - x_logits_ssim: -0.0031 - x_logits_sharpdiff: 4.2403 - x_logits_mean_absolute_error: 0.1557 - x_logits_mean_squared_error: 0.082 - ETA: 0s - loss: 1018.1896 - covariance_regularized_loss: 4.6637 - x_logits_loss: 1013.4310 - x_logits_psnr: 10.8204 - x_logits_ssim: -0.0033 - x_logits_sharpdiff: 4.2447 - x_logits_mean_absolute_error: 0.1560 - x_logits_mean_squared_error: 0.083 - 1s 62ms/step - loss: 1012.7601 - covariance_regularized_loss: 4.6782 - x_logits_loss: 1007.9869 - x_logits_psnr: 10.8341 - x_logits_ssim: -0.0033 - x_logits_sharpdiff: 4.2438 - x_logits_mean_absolute_error: 0.1558 - x_logits_mean_squared_error: 0.0829 - val_loss: 734.4385 - val_covariance_regularized_loss: 16.8503 - val_x_logits_loss: 717.5231 - val_x_logits_psnr: 14.3973 - val_x_logits_ssim: -0.0044 - val_x_logits_sharpdiff: 17.8444 - val_x_logits_mean_absolute_error: 0.0691 - val_x_logits_mean_squared_error: 0.0411\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 984.2816 - covariance_regularized_loss: 4.7804 - x_logits_loss: 979.4059 - x_logits_psnr: 10.9288 - x_logits_ssim: -0.0048 - x_logits_sharpdiff: 4.2614 - x_logits_mean_absolute_error: 0.1543 - x_logits_mean_squared_error: 0.081 - ETA: 0s - loss: 958.5888 - covariance_regularized_loss: 5.0865 - x_logits_loss: 953.4070 - x_logits_psnr: 11.0049 - x_logits_ssim: -0.0045 - x_logits_sharpdiff: 4.2739 - x_logits_mean_absolute_error: 0.1526 - x_logits_mean_squared_error: 0.079 - ETA: 0s - loss: 967.6987 - covariance_regularized_loss: 4.8711 - x_logits_loss: 962.7323 - x_logits_psnr: 10.9633 - x_logits_ssim: -0.0047 - x_logits_sharpdiff: 4.2707 - x_logits_mean_absolute_error: 0.1537 - x_logits_mean_squared_error: 0.080 - ETA: 0s - loss: 962.1650 - covariance_regularized_loss: 4.7721 - x_logits_loss: 957.2975 - x_logits_psnr: 10.9802 - x_logits_ssim: -0.0049 - x_logits_sharpdiff: 4.2764 - x_logits_mean_absolute_error: 0.1534 - x_logits_mean_squared_error: 0.080 - ETA: 0s - loss: 953.2591 - covariance_regularized_loss: 4.7985 - x_logits_loss: 948.3652 - x_logits_psnr: 11.0120 - x_logits_ssim: -0.0049 - x_logits_sharpdiff: 4.2814 - x_logits_mean_absolute_error: 0.1527 - x_logits_mean_squared_error: 0.079 - 1s 61ms/step - loss: 951.1338 - covariance_regularized_loss: 4.7983 - x_logits_loss: 946.2401 - x_logits_psnr: 11.0181 - x_logits_ssim: -0.0050 - x_logits_sharpdiff: 4.2830 - x_logits_mean_absolute_error: 0.1526 - x_logits_mean_squared_error: 0.0794 - val_loss: 725.1746 - val_covariance_regularized_loss: 15.9429 - val_x_logits_loss: 709.1661 - val_x_logits_psnr: 14.3692 - val_x_logits_ssim: -0.0057 - val_x_logits_sharpdiff: 17.8379 - val_x_logits_mean_absolute_error: 0.0690 - val_x_logits_mean_squared_error: 0.0413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a70eb21588>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit(\n",
    "    x=train_ds,\n",
    "    input_kw='image',\n",
    "    steps_per_epoch=10,\n",
    "    epochs=10,#int(1e6), \n",
    "    verbose=1,\n",
    "    callbacks=[ es, ms, csv_log, sg],#, gts_mertics, gtu_mertics],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 75x75; got `input_shape=[64, 64, 3]`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-c26df8749365>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mis_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_sigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minception_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'inception_score mean: {is_mean}, sigma: {is_sigma}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\evaluation\\generativity_metrics\\inception_metrics.py\u001b[0m in \u001b[0;36minception_score\u001b[1;34m(model, tolerance_threshold, max_iteration)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# prepare the inception v3 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minputs_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_inputs_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0minception_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'avg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0minception_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minception_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minception_preprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\keras_applications\\inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mrequire_flatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         weights=weights)\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\keras_applications\\imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    320\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'x'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                                      \u001b[1;34m'; got `input_shape='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                                      str(input_shape) + '`')\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrequire_flatten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input size must be at least 75x75; got `input_shape=[64, 64, 3]`"
     ]
    }
   ],
   "source": [
    "is_mean, is_sigma = inception_score(ae, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'inception_score mean: {is_mean}, sigma: {is_sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-f7960b05bb3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfis_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrechet_inception_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'frechet inception distance: {fis_score}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "fis_score = frechet_inception_distance(ae, training_generator, tolerance_threshold=1e-6, max_iteration=10, batch_size=32)\n",
    "print(f'frechet inception distance: {fis_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.perceptual_path_length import perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_mean_score = perceptual_path_length_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100, batch_size=32)\n",
    "print(f'perceptual path length score: {ppl_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_precision_score = precision_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'precision score: {_precision_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_recall_score = recall_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'recall score: {_recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import reconstruct_from_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_like_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'random_synthetic_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_randomly(ae, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import interpolate_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'interpolate_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "interpolate_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
