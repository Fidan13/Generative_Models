{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "\n",
    "import sys\n",
    "sys.path.append('..'+sep_local+'..')\n",
    "print(sep_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalid\\Documents\\projects\\Generative_Models\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='dsprites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape= image_size=(64, 64, 1)\n",
    "batch_size = 32\n",
    "latents_dim = 32\n",
    "intermediate_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='dsprites',\n",
      "    version=0.1.0,\n",
      "    description='dSprites is a dataset of 2D shapes procedurally generated from 6 ground truth\n",
      "independent latent factors. These factors are *color*, *shape*, *scale*,\n",
      "*rotation*, *x* and *y* positions of a sprite.\n",
      "\n",
      "All possible combinations of these latents are present exactly once,\n",
      "generating N = 737280 total images.\n",
      "\n",
      "### Latent factor values\n",
      "\n",
      "*   Color: white\n",
      "*   Shape: square, ellipse, heart\n",
      "*   Scale: 6 values linearly spaced in [0.5, 1]\n",
      "*   Orientation: 40 values in [0, 2 pi]\n",
      "*   Position X: 32 values in [0, 1]\n",
      "*   Position Y: 32 values in [0, 1]\n",
      "\n",
      "We varied one latent at a time (starting from Position Y, then Position X, etc),\n",
      "and sequentially stored the images in fixed order.\n",
      "Hence the order along the first dimension is fixed and allows you to map back to\n",
      "the value of the latents corresponding to that image.\n",
      "\n",
      "We chose the latents values deliberately to have the smallest step changes\n",
      "while ensuring that all pixel outputs were different. No noise was added.\n",
      "',\n",
      "    urls=['https://github.com/deepmind/dsprites-dataset'],\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(64, 64, 1), dtype=tf.uint8),\n",
      "        'label_orientation': ClassLabel(shape=(), dtype=tf.int64, num_classes=40),\n",
      "        'label_scale': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),\n",
      "        'label_shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "        'label_x_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'label_y_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'value_orientation': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_scale': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_shape': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_x_position': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_y_position': Tensor(shape=[], dtype=tf.float32),\n",
      "    }),\n",
      "    total_num_examples=737280,\n",
      "    splits={\n",
      "        'train': 737280,\n",
      "    },\n",
      "    supervised_keys=None,\n",
      "    citation=\"\"\"@misc{dsprites17,\n",
      "    author = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},\n",
      "    title = {dSprites: Disentanglement testing Sprites dataset},\n",
      "    howpublished= {https://github.com/deepmind/dsprites-dataset/},\n",
      "    year = \"2017\",\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "info = tfds.builder(dataset_name).info\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BUF = 600\n",
    "TEST_BUF = 100\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "# Construct a tf.data.Dataset\n",
    "train_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TRAIN_BUF).batch(batch_size)\n",
    "try:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TEST).shuffle(TEST_BUF).batch(batch_size)\n",
    "except:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TRAIN_BUF).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data['image'].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_instance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(inputs_shape, Iterable):\n",
    "    _outputs_shape = np.prod(inputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_outputs_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=20\n",
    "c=16\n",
    "enc_lays = [\n",
    "    tf.keras.layers.Conv2D(filters=units, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=units*9, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latents_dim)\n",
    "]\n",
    "\n",
    "dec_lays = [\n",
    "    tf.keras.layers.Dense(units=c*c*units, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Reshape(target_shape=(c , c, units)),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=units, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=units*3, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    \n",
    "    # No activation\n",
    "    tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'DIP_Cov_AE_Convolutional_reconst_ellwlb'\n",
    "experiments_dir='experiments'+sep_local+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.regularized.disentangled_inferred_prior.DIP_Covariance_AE import DIP_Covariance_AE as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape=image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latents_dim,\n",
    "        'layers': enc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latents_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(experiments_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb\\\\var_save_dir'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exist(_restore)\n",
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to restore trained model, set filepath=_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inference\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 31, 31, 20)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 180)       32580     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40500)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1296032   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 1,328,940\n",
      "Trainable params: 1,328,876\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generative\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5120)              168960    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 20)        3620      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 64, 64, 60)        10860     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 1)         541       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 1)         4         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 64, 64, 1)         0         \n",
      "=================================================================\n",
      "Total params: 183,985\n",
      "Trainable params: 183,983\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    }
   ],
   "source": [
    "ae = AE( \n",
    "    name=model_name,\n",
    "    latents_dim=latents_dim,\n",
    "    batch_size=batch_size,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inference_inputs (InputLayer)   [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inference (Model)               (None, 32)           1328940     inference_inputs[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 32, 1)]      0           inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 32)]      0           inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(32,)]              0           inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None, 32, 32)]     0           tf_op_layer_ExpandDims[0][0]     \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(32, 1)]            0           tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(1, 32)]            0           tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(32, 32)]           0           tf_op_layer_mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(32, 32)]           0           tf_op_layer_ExpandDims_2[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_covariance_mean (Te [(32, 32)]           0           tf_op_layer_Mean[0][0]           \n",
      "                                                                 tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_diag_part (TensorFl [(32,)]              0           tf_op_layer_covariance_mean[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_diag (TensorFlowOpL [(32, 32)]           0           tf_op_layer_diag_part[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(32, 32)]           0           tf_op_layer_covariance_mean[0][0]\n",
      "                                                                 tf_op_layer_diag[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_1 (TensorFlowOp [(32,)]              0           tf_op_layer_diag_part[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow (TensorFlowOpLa [(32, 32)]           0           tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow_1 (TensorFlowOp [(32,)]              0           tf_op_layer_sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_2 (TensorFlowOp [(32, 32)]           0           tf_op_layer_pow[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_3 (TensorFlowOp [(32,)]              0           tf_op_layer_pow_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add (TensorFlowOpLa [(32, 32)]           0           tf_op_layer_mul_2[0][0]          \n",
      "                                                                 tf_op_layer_mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "generative (Model)              (None, 64, 64, 1)    183985      inference[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_covariance_regulari [(32, 32)]           0           tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_x_logits (TensorFlo [(None, 64, 64, 1)]  0           generative[1][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,512,925\n",
      "Trainable params: 1,512,859\n",
      "Non-trainable params: 66\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#ae.compile(metrics=None)\n",
    "ae.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore,save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb\\\\csv_dir\\\\dspritesDIP_Cov_AE_Convolutional_reconst_ellwlb.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir = os.path.join(experiments_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, ae.name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(experiments_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latents_shape=latents_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "#DATA_DOWN_PATH = '..'+sep_local+'..'+sep_local+'..'+sep_local+'data'\n",
    "DATA_DOWN_PATH = os.getcwd() + sep_local+'data'\n",
    "Script_dir = os.getcwd() + sep_local+'data'+sep_local+'download_gt_data.sh'\n",
    "# Script call to download \"dsprites_full\" dataset_name \n",
    "!/bin/bash $Script_dir -f $DATA_DOWN_PATH -d $dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH C:\\Users\\Khalid\\Documents\\projects\\Generative_Models\\data\\.gt_datasets\n"
     ]
    }
   ],
   "source": [
    "from os.path import abspath\n",
    "\n",
    "from data.gt_load.datasets import load\n",
    "DATA_PATH = DATA_DOWN_PATH +sep_local+'.gt_datasets'\n",
    "absolute = abspath(DATA_PATH)\n",
    "print(\"DATA_PATH\",absolute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_dataset = load(dataset_name='dsprites_full', dataset_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.callbacks.disentangle_supervied import DisentanglementSuperviedMetrics\n",
    "from training.callbacks.disentangle_unsupervied import DisentanglementUnsuperviedMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gts_mertics = DisentanglementSuperviedMetrics(            \n",
    "#    ground_truth_data=eval_dataset,\n",
    "#    representation_fn=lambda x: ae.encode(x),\n",
    "#    random_state=np.random.RandomState(0),\n",
    "#    file_Name=gts_csv,\n",
    "#    num_train=10000,\n",
    "#    num_test=100,\n",
    "#    batch_size=batch_size,\n",
    "#    continuous_factors=False,\n",
    "#    gt_freq=10\n",
    "#)\n",
    "#gtu_mertics = DisentanglementUnsuperviedMetrics(            \n",
    "#    ground_truth_data=eval_dataset,\n",
    "#    representation_fn=lambda x: ae.encode(x),\n",
    "#    random_state=np.random.RandomState(0),\n",
    "#    file_Name=gtu_csv,\n",
    "#    num_train=10000,\n",
    "#    num_test=100,\n",
    "#    batch_size=batch_size,\n",
    "#    gt_freq=10\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 40s - loss: 2896.9956 - covariance_regularized_loss: 53.2661 - x_logits_loss: 2843.7290 - x_logits_psnr: 6.0115 - x_logits_ssim: 0.0375 - x_logits_sharpdiff: 10.7133 - x_logits_mean_absolute_error: 0.4998 - x_logits_mean_squared_error: 0.25 - ETA: 10s - loss: 1834.6808 - covariance_regularized_loss: 33.1116 - x_logits_loss: 1801.5416 - x_logits_psnr: 8.8795 - x_logits_ssim: 0.0125 - x_logits_sharpdiff: 6.5511 - x_logits_mean_absolute_error: 0.2952 - x_logits_mean_squared_error: 0.1463 - ETA: 4s - loss: 1666.7964 - covariance_regularized_loss: 29.8534 - x_logits_loss: 1636.8920 - x_logits_psnr: 9.4085 - x_logits_ssim: 0.0075 - x_logits_sharpdiff: 5.6416 - x_logits_mean_absolute_error: 0.2434 - x_logits_mean_squared_error: 0.126 - ETA: 2s - loss: 1598.7956 - covariance_regularized_loss: 30.0654 - x_logits_loss: 1568.6669 - x_logits_psnr: 9.6479 - x_logits_ssim: 0.0054 - x_logits_sharpdiff: 5.2494 - x_logits_mean_absolute_error: 0.2206 - x_logits_mean_squared_error: 0.11 - ETA: 0s - loss: 1559.6998 - covariance_regularized_loss: 28.4681 - x_logits_loss: 1531.1614 - x_logits_psnr: 9.7805 - x_logits_ssim: 0.0042 - x_logits_sharpdiff: 5.0305 - x_logits_mean_absolute_error: 0.2080 - x_logits_mean_squared_error: 0.11 - 6s 620ms/step - loss: 1539.7555 - covariance_regularized_loss: 27.6323 - x_logits_loss: 1512.0504 - x_logits_psnr: 9.8395 - x_logits_ssim: 0.0037 - x_logits_sharpdiff: 4.9541 - x_logits_mean_absolute_error: 0.2033 - x_logits_mean_squared_error: 0.1108 - val_loss: 808.4166 - val_covariance_regularized_loss: 73.7244 - val_x_logits_loss: 734.6239 - val_x_logits_psnr: 14.4159 - val_x_logits_ssim: -0.0040 - val_x_logits_sharpdiff: 17.9586 - val_x_logits_mean_absolute_error: 0.0664 - val_x_logits_mean_squared_error: 0.0408\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1358.6715 - covariance_regularized_loss: 23.1109 - x_logits_loss: 1335.4662 - x_logits_psnr: 10.3751 - x_logits_ssim: -4.9430e-05 - x_logits_sharpdiff: 4.2730 - x_logits_mean_absolute_error: 0.1605 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1391.9225 - covariance_regularized_loss: 26.0058 - x_logits_loss: 1365.8223 - x_logits_psnr: 10.3230 - x_logits_ssim: -2.2382e-05 - x_logits_sharpdiff: 4.2817 - x_logits_mean_absolute_error: 0.1620 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1397.6466 - covariance_regularized_loss: 24.0540 - x_logits_loss: 1373.4983 - x_logits_psnr: 10.2985 - x_logits_ssim: 2.5401e-05 - x_logits_sharpdiff: 4.2737 - x_logits_mean_absolute_error: 0.1625 - x_logits_mean_squared_error: 0.0947 - ETA: 0s - loss: 1396.3540 - covariance_regularized_loss: 24.4313 - x_logits_loss: 1371.8282 - x_logits_psnr: 10.2996 - x_logits_ssim: 3.0497e-05 - x_logits_sharpdiff: 4.2747 - x_logits_mean_absolute_error: 0.1624 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1381.8308 - covariance_regularized_loss: 24.8346 - x_logits_loss: 1356.9017 - x_logits_psnr: 10.3303 - x_logits_ssim: 2.0167e-05 - x_logits_sharpdiff: 4.2723 - x_logits_mean_absolute_error: 0.1618 - x_logits_mean_squared_error: 0.094 - 1s 63ms/step - loss: 1388.2724 - covariance_regularized_loss: 24.4131 - x_logits_loss: 1363.7649 - x_logits_psnr: 10.3141 - x_logits_ssim: 2.0871e-05 - x_logits_sharpdiff: 4.2739 - x_logits_mean_absolute_error: 0.1621 - x_logits_mean_squared_error: 0.0943 - val_loss: 812.8343 - val_covariance_regularized_loss: 70.1185 - val_x_logits_loss: 742.6475 - val_x_logits_psnr: 14.3826 - val_x_logits_ssim: -0.0042 - val_x_logits_sharpdiff: 17.9420 - val_x_logits_mean_absolute_error: 0.0669 - val_x_logits_mean_squared_error: 0.0413\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1422.5752 - covariance_regularized_loss: 20.9805 - x_logits_loss: 1401.5002 - x_logits_psnr: 10.2293 - x_logits_ssim: 7.0501e-05 - x_logits_sharpdiff: 4.2627 - x_logits_mean_absolute_error: 0.1643 - x_logits_mean_squared_error: 0.096 - ETA: 0s - loss: 1384.9187 - covariance_regularized_loss: 21.9142 - x_logits_loss: 1362.9103 - x_logits_psnr: 10.2984 - x_logits_ssim: 7.8168e-05 - x_logits_sharpdiff: 4.2491 - x_logits_mean_absolute_error: 0.1628 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1390.7637 - covariance_regularized_loss: 22.3971 - x_logits_loss: 1368.2722 - x_logits_psnr: 10.2832 - x_logits_ssim: 6.4877e-05 - x_logits_sharpdiff: 4.2565 - x_logits_mean_absolute_error: 0.1631 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1381.5235 - covariance_regularized_loss: 23.0536 - x_logits_loss: 1358.3754 - x_logits_psnr: 10.3036 - x_logits_ssim: 2.6835e-05 - x_logits_sharpdiff: 4.2646 - x_logits_mean_absolute_error: 0.1625 - x_logits_mean_squared_error: 0.094 - ETA: 0s - loss: 1389.6169 - covariance_regularized_loss: 23.1725 - x_logits_loss: 1366.3499 - x_logits_psnr: 10.2814 - x_logits_ssim: 4.9839e-06 - x_logits_sharpdiff: 4.2665 - x_logits_mean_absolute_error: 0.1629 - x_logits_mean_squared_error: 0.094 - 1s 64ms/step - loss: 1384.5815 - covariance_regularized_loss: 23.1524 - x_logits_loss: 1361.3346 - x_logits_psnr: 10.2911 - x_logits_ssim: -2.5238e-06 - x_logits_sharpdiff: 4.2681 - x_logits_mean_absolute_error: 0.1627 - x_logits_mean_squared_error: 0.0947 - val_loss: 826.5282 - val_covariance_regularized_loss: 67.2514 - val_x_logits_loss: 759.2085 - val_x_logits_psnr: 14.2735 - val_x_logits_ssim: -0.0045 - val_x_logits_sharpdiff: 17.8894 - val_x_logits_mean_absolute_error: 0.0680 - val_x_logits_mean_squared_error: 0.0424\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1298.9443 - covariance_regularized_loss: 25.2343 - x_logits_loss: 1273.6157 - x_logits_psnr: 10.4721 - x_logits_ssim: -6.9969e-05 - x_logits_sharpdiff: 4.2475 - x_logits_mean_absolute_error: 0.1592 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1370.1271 - covariance_regularized_loss: 23.9870 - x_logits_loss: 1346.0455 - x_logits_psnr: 10.2989 - x_logits_ssim: -5.4862e-05 - x_logits_sharpdiff: 4.2661 - x_logits_mean_absolute_error: 0.1624 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1392.6379 - covariance_regularized_loss: 23.1247 - x_logits_loss: 1369.4187 - x_logits_psnr: 10.2417 - x_logits_ssim: -1.2498e-04 - x_logits_sharpdiff: 4.2646 - x_logits_mean_absolute_error: 0.1637 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1380.2779 - covariance_regularized_loss: 22.9935 - x_logits_loss: 1357.1898 - x_logits_psnr: 10.2622 - x_logits_ssim: -9.1348e-05 - x_logits_sharpdiff: 4.2596 - x_logits_mean_absolute_error: 0.1633 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1371.6387 - covariance_regularized_loss: 24.4623 - x_logits_loss: 1347.0817 - x_logits_psnr: 10.2802 - x_logits_ssim: -1.0728e-04 - x_logits_sharpdiff: 4.2620 - x_logits_mean_absolute_error: 0.1629 - x_logits_mean_squared_error: 0.09 - 1s 64ms/step - loss: 1363.8188 - covariance_regularized_loss: 23.9655 - x_logits_loss: 1339.7585 - x_logits_psnr: 10.2970 - x_logits_ssim: -1.0516e-04 - x_logits_sharpdiff: 4.2649 - x_logits_mean_absolute_error: 0.1626 - x_logits_mean_squared_error: 0.0945 - val_loss: 840.7699 - val_covariance_regularized_loss: 64.0545 - val_x_logits_loss: 776.6473 - val_x_logits_psnr: 14.1318 - val_x_logits_ssim: -0.0047 - val_x_logits_sharpdiff: 17.8186 - val_x_logits_mean_absolute_error: 0.0692 - val_x_logits_mean_squared_error: 0.0436\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 1336.9962 - covariance_regularized_loss: 29.0659 - x_logits_loss: 1307.8358 - x_logits_psnr: 10.3219 - x_logits_ssim: -1.6089e-04 - x_logits_sharpdiff: 4.2351 - x_logits_mean_absolute_error: 0.1626 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1305.4056 - covariance_regularized_loss: 27.5570 - x_logits_loss: 1277.7539 - x_logits_psnr: 10.3987 - x_logits_ssim: -1.3861e-04 - x_logits_sharpdiff: 4.2542 - x_logits_mean_absolute_error: 0.1606 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1302.8557 - covariance_regularized_loss: 25.3183 - x_logits_loss: 1277.4426 - x_logits_psnr: 10.3908 - x_logits_ssim: -1.9813e-04 - x_logits_sharpdiff: 4.2597 - x_logits_mean_absolute_error: 0.1607 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1311.6899 - covariance_regularized_loss: 24.8830 - x_logits_loss: 1286.7122 - x_logits_psnr: 10.3570 - x_logits_ssim: -1.9021e-04 - x_logits_sharpdiff: 4.2570 - x_logits_mean_absolute_error: 0.1616 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1302.0687 - covariance_regularized_loss: 24.6093 - x_logits_loss: 1277.3646 - x_logits_psnr: 10.3676 - x_logits_ssim: -2.1132e-04 - x_logits_sharpdiff: 4.2577 - x_logits_mean_absolute_error: 0.1613 - x_logits_mean_squared_error: 0.09 - 1s 64ms/step - loss: 1298.6499 - covariance_regularized_loss: 24.4753 - x_logits_loss: 1274.0798 - x_logits_psnr: 10.3700 - x_logits_ssim: -2.4395e-04 - x_logits_sharpdiff: 4.2611 - x_logits_mean_absolute_error: 0.1612 - x_logits_mean_squared_error: 0.0930 - val_loss: 828.4667 - val_covariance_regularized_loss: 61.0136 - val_x_logits_loss: 767.3848 - val_x_logits_psnr: 14.1774 - val_x_logits_ssim: -0.0046 - val_x_logits_sharpdiff: 17.8578 - val_x_logits_mean_absolute_error: 0.0686 - val_x_logits_mean_squared_error: 0.0430\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1291.4048 - covariance_regularized_loss: 23.9392 - x_logits_loss: 1267.3705 - x_logits_psnr: 10.3104 - x_logits_ssim: -3.5625e-04 - x_logits_sharpdiff: 4.2550 - x_logits_mean_absolute_error: 0.1626 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1276.4705 - covariance_regularized_loss: 25.6377 - x_logits_loss: 1250.7379 - x_logits_psnr: 10.3414 - x_logits_ssim: -5.7678e-04 - x_logits_sharpdiff: 4.2562 - x_logits_mean_absolute_error: 0.1621 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1260.8556 - covariance_regularized_loss: 24.8587 - x_logits_loss: 1235.9017 - x_logits_psnr: 10.3722 - x_logits_ssim: -6.0064e-04 - x_logits_sharpdiff: 4.2640 - x_logits_mean_absolute_error: 0.1614 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1244.6388 - covariance_regularized_loss: 24.4638 - x_logits_loss: 1220.0798 - x_logits_psnr: 10.4010 - x_logits_ssim: -6.9061e-04 - x_logits_sharpdiff: 4.2660 - x_logits_mean_absolute_error: 0.1608 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1232.3555 - covariance_regularized_loss: 24.7103 - x_logits_loss: 1207.5499 - x_logits_psnr: 10.4194 - x_logits_ssim: -7.7524e-04 - x_logits_sharpdiff: 4.2679 - x_logits_mean_absolute_error: 0.1605 - x_logits_mean_squared_error: 0.09 - 1s 107ms/step - loss: 1234.7963 - covariance_regularized_loss: 24.5876 - x_logits_loss: 1210.1134 - x_logits_psnr: 10.4060 - x_logits_ssim: -8.2603e-04 - x_logits_sharpdiff: 4.2668 - x_logits_mean_absolute_error: 0.1610 - x_logits_mean_squared_error: 0.0920 - val_loss: 807.4234 - val_covariance_regularized_loss: 55.8351 - val_x_logits_loss: 751.5198 - val_x_logits_psnr: 14.2459 - val_x_logits_ssim: -0.0040 - val_x_logits_sharpdiff: 17.8547 - val_x_logits_mean_absolute_error: 0.0676 - val_x_logits_mean_squared_error: 0.0422\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1170.6023 - covariance_regularized_loss: 19.3203 - x_logits_loss: 1151.1864 - x_logits_psnr: 10.4912 - x_logits_ssim: -0.0012 - x_logits_sharpdiff: 4.2753 - x_logits_mean_absolute_error: 0.1598 - x_logits_mean_squared_error: 0.09 - ETA: 0s - loss: 1149.0200 - covariance_regularized_loss: 22.4982 - x_logits_loss: 1126.4263 - x_logits_psnr: 10.5466 - x_logits_ssim: -0.0014 - x_logits_sharpdiff: 4.2443 - x_logits_mean_absolute_error: 0.1590 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1140.7780 - covariance_regularized_loss: 22.3978 - x_logits_loss: 1118.2845 - x_logits_psnr: 10.5549 - x_logits_ssim: -0.0016 - x_logits_sharpdiff: 4.2427 - x_logits_mean_absolute_error: 0.1592 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1140.9786 - covariance_regularized_loss: 22.9339 - x_logits_loss: 1117.9490 - x_logits_psnr: 10.5506 - x_logits_ssim: -0.0018 - x_logits_sharpdiff: 4.2418 - x_logits_mean_absolute_error: 0.1594 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1127.7233 - covariance_regularized_loss: 22.8898 - x_logits_loss: 1104.7377 - x_logits_psnr: 10.5841 - x_logits_ssim: -0.0020 - x_logits_sharpdiff: 4.2442 - x_logits_mean_absolute_error: 0.1589 - x_logits_mean_squared_error: 0.08 - 1s 64ms/step - loss: 1128.1566 - covariance_regularized_loss: 23.7120 - x_logits_loss: 1104.3488 - x_logits_psnr: 10.5823 - x_logits_ssim: -0.0020 - x_logits_sharpdiff: 4.2429 - x_logits_mean_absolute_error: 0.1590 - x_logits_mean_squared_error: 0.0881 - val_loss: 784.2065 - val_covariance_regularized_loss: 50.8132 - val_x_logits_loss: 733.3245 - val_x_logits_psnr: 14.3393 - val_x_logits_ssim: -0.0037 - val_x_logits_sharpdiff: 17.9010 - val_x_logits_mean_absolute_error: 0.0666 - val_x_logits_mean_squared_error: 0.0415\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1019.5366 - covariance_regularized_loss: 19.9239 - x_logits_loss: 999.5162 - x_logits_psnr: 10.8626 - x_logits_ssim: -0.0033 - x_logits_sharpdiff: 4.2554 - x_logits_mean_absolute_error: 0.1540 - x_logits_mean_squared_error: 0.082 - ETA: 0s - loss: 1055.8498 - covariance_regularized_loss: 21.9302 - x_logits_loss: 1033.8229 - x_logits_psnr: 10.7451 - x_logits_ssim: -0.0032 - x_logits_sharpdiff: 4.2481 - x_logits_mean_absolute_error: 0.1564 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1054.3500 - covariance_regularized_loss: 22.3400 - x_logits_loss: 1031.9132 - x_logits_psnr: 10.7472 - x_logits_ssim: -0.0033 - x_logits_sharpdiff: 4.2470 - x_logits_mean_absolute_error: 0.1565 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1042.5825 - covariance_regularized_loss: 21.8302 - x_logits_loss: 1020.6554 - x_logits_psnr: 10.7860 - x_logits_ssim: -0.0034 - x_logits_sharpdiff: 4.2525 - x_logits_mean_absolute_error: 0.1558 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1038.6293 - covariance_regularized_loss: 22.0857 - x_logits_loss: 1016.4466 - x_logits_psnr: 10.7947 - x_logits_ssim: -0.0036 - x_logits_sharpdiff: 4.2525 - x_logits_mean_absolute_error: 0.1557 - x_logits_mean_squared_error: 0.08 - 1s 63ms/step - loss: 1038.0560 - covariance_regularized_loss: 21.8364 - x_logits_loss: 1016.1227 - x_logits_psnr: 10.7897 - x_logits_ssim: -0.0038 - x_logits_sharpdiff: 4.2504 - x_logits_mean_absolute_error: 0.1559 - x_logits_mean_squared_error: 0.0838 - val_loss: 768.6517 - val_covariance_regularized_loss: 50.1086 - val_x_logits_loss: 718.4738 - val_x_logits_psnr: 14.4060 - val_x_logits_ssim: -0.0041 - val_x_logits_sharpdiff: 17.9040 - val_x_logits_mean_absolute_error: 0.0659 - val_x_logits_mean_squared_error: 0.0410\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 1057.5160 - covariance_regularized_loss: 27.1311 - x_logits_loss: 1030.2875 - x_logits_psnr: 10.7366 - x_logits_ssim: -0.0048 - x_logits_sharpdiff: 4.2504 - x_logits_mean_absolute_error: 0.1574 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1027.7896 - covariance_regularized_loss: 23.9467 - x_logits_loss: 1003.7455 - x_logits_psnr: 10.8283 - x_logits_ssim: -0.0046 - x_logits_sharpdiff: 4.2662 - x_logits_mean_absolute_error: 0.1553 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 1015.3805 - covariance_regularized_loss: 23.6715 - x_logits_loss: 991.6117 - x_logits_psnr: 10.8672 - x_logits_ssim: -0.0046 - x_logits_sharpdiff: 4.2542 - x_logits_mean_absolute_error: 0.1549 - x_logits_mean_squared_error: 0.0823 - ETA: 0s - loss: 998.0699 - covariance_regularized_loss: 21.4010 - x_logits_loss: 976.5717 - x_logits_psnr: 10.9127 - x_logits_ssim: -0.0046 - x_logits_sharpdiff: 4.2511 - x_logits_mean_absolute_error: 0.1541 - x_logits_mean_squared_error: 0.081 - ETA: 0s - loss: 985.9986 - covariance_regularized_loss: 21.5943 - x_logits_loss: 964.3069 - x_logits_psnr: 10.9593 - x_logits_ssim: -0.0045 - x_logits_sharpdiff: 4.2563 - x_logits_mean_absolute_error: 0.1532 - x_logits_mean_squared_error: 0.08 - 1s 64ms/step - loss: 985.7438 - covariance_regularized_loss: 21.3039 - x_logits_loss: 964.3426 - x_logits_psnr: 10.9578 - x_logits_ssim: -0.0046 - x_logits_sharpdiff: 4.2573 - x_logits_mean_absolute_error: 0.1533 - x_logits_mean_squared_error: 0.0805 - val_loss: 759.0699 - val_covariance_regularized_loss: 46.9818 - val_x_logits_loss: 712.0183 - val_x_logits_psnr: 14.3619 - val_x_logits_ssim: -0.0052 - val_x_logits_sharpdiff: 17.8758 - val_x_logits_mean_absolute_error: 0.0658 - val_x_logits_mean_squared_error: 0.0412\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 994.3822 - covariance_regularized_loss: 23.1382 - x_logits_loss: 971.1466 - x_logits_psnr: 10.8774 - x_logits_ssim: -0.0062 - x_logits_sharpdiff: 4.2474 - x_logits_mean_absolute_error: 0.1559 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 981.8698 - covariance_regularized_loss: 20.1146 - x_logits_loss: 961.6575 - x_logits_psnr: 10.9476 - x_logits_ssim: -0.0054 - x_logits_sharpdiff: 4.2613 - x_logits_mean_absolute_error: 0.1542 - x_logits_mean_squared_error: 0.08 - ETA: 0s - loss: 961.2756 - covariance_regularized_loss: 20.6067 - x_logits_loss: 940.5714 - x_logits_psnr: 11.0299 - x_logits_ssim: -0.0052 - x_logits_sharpdiff: 4.2643 - x_logits_mean_absolute_error: 0.1526 - x_logits_mean_squared_error: 0.07 - ETA: 0s - loss: 964.4043 - covariance_regularized_loss: 20.8223 - x_logits_loss: 943.4843 - x_logits_psnr: 11.0185 - x_logits_ssim: -0.0053 - x_logits_sharpdiff: 4.2690 - x_logits_mean_absolute_error: 0.1527 - x_logits_mean_squared_error: 0.07 - ETA: 0s - loss: 962.3213 - covariance_regularized_loss: 20.2636 - x_logits_loss: 941.9600 - x_logits_psnr: 11.0247 - x_logits_ssim: -0.0054 - x_logits_sharpdiff: 4.2691 - x_logits_mean_absolute_error: 0.1526 - x_logits_mean_squared_error: 0.07 - 1s 62ms/step - loss: 964.7124 - covariance_regularized_loss: 20.3463 - x_logits_loss: 944.2684 - x_logits_psnr: 11.0170 - x_logits_ssim: -0.0055 - x_logits_sharpdiff: 4.2695 - x_logits_mean_absolute_error: 0.1527 - x_logits_mean_squared_error: 0.0794 - val_loss: 745.9977 - val_covariance_regularized_loss: 47.0366 - val_x_logits_loss: 698.8907 - val_x_logits_psnr: 14.4163 - val_x_logits_ssim: -0.0064 - val_x_logits_sharpdiff: 17.8458 - val_x_logits_mean_absolute_error: 0.0653 - val_x_logits_mean_squared_error: 0.0409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27f8febda48>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit(\n",
    "    x=train_ds,\n",
    "    input_kw='image',\n",
    "    steps_per_epoch=10,\n",
    "    epochs=10,#int(1e6), \n",
    "    verbose=1,\n",
    "    callbacks=[ es, ms, csv_log, sg],#, gts_mertics, gtu_mertics],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the inception_score mean ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [03:40, 44.10s/it]"
     ]
    }
   ],
   "source": [
    "is_mean, is_sigma = inception_score(ae, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'inception_score mean: {is_mean}, sigma: {is_sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis_score = frechet_inception_distance(ae, training_generator, tolerance_threshold=1e-6, max_iteration=10, batch_size=32)\n",
    "print(f'frechet inception distance: {fis_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.perceptual_path_length import perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_mean_score = perceptual_path_length_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100, batch_size=32)\n",
    "print(f'perceptual path length score: {ppl_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_precision_score = precision_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'precision score: {_precision_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_recall_score = recall_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'recall score: {_recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import reconstruct_from_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_like_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'random_synthetic_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_randomly(ae, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import interpolate_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'interpolate_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "interpolate_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
